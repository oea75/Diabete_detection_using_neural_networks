{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetes detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7FU331UsfpvJK3fGyuIHW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HioPu8IHVaXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This program detects if a patient has diabetes or not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA6q0dIwWdqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a84aa9ed-ee92-45a2-df3b-dfdb08643c5f"
      },
      "source": [
        "# load libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4HN7hVaXSw3",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5aa72410-e44a-41a7-a8bd-d2e53f6cb743"
      },
      "source": [
        "# load the data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b63f03f-e56c-4194-a7a3-d80e2778a0aa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b63f03f-e56c-4194-a7a3-d80e2778a0aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving diabetes.csv to diabetes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLFaVonYXrZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9eb50cfb-a8d2-414e-b231-9104322ae2ea"
      },
      "source": [
        "# store the dataset\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# print the first 5 rows of data\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eV7NEqfX1m3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2969097-c523-4c0e-d358-d816e4aea7e8"
      },
      "source": [
        "# show the data shape\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vexY01-YHiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7712e17a-a270-40e8-d61c-a8d6cef2439e"
      },
      "source": [
        "# check for duplicates if any & remove them\n",
        "df.drop_duplicates(inplace = True)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXnWdWtZYVY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d24fb2c2-5363-4452-bb5a-6b01a6508647"
      },
      "source": [
        "# show the number of missing data for each column\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVYgf8EkYoLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "21275444-7b6b-4d2b-c571-961bead693fb"
      },
      "source": [
        "# convert the data into an array\n",
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLlV4Dm7ZBNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all of the rows from the first eight columns of the dataset\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFpO8qA5ZXyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "904d8bbf-9204-4820-b217-72121644c405"
      },
      "source": [
        "# process the data\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3nBH6aPZp9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data into 80% training & 20% testing\n",
        "X_train, X_test,y_train, y_test = train_test_split(X_scale, y, test_size=0.2, random_state = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZVgkc9faGKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "model = Sequential([\n",
        "    Dense(12, activation='relu', input_shape=(8,)),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "\n",
        "]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOw_YhYaty1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(\n",
        "    optimizer = 'sgd', \n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-qBqVAzbarJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e3f5a417-4c09-4c24-9828-924ab0a44adf"
      },
      "source": [
        "print('X_train shape: ',X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (614, 8)\n",
            "X_test shape:  (154, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61-qR4l6a_7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f9da712-64d8-430d-975f-7acd4670e7bb"
      },
      "source": [
        "# train the model\n",
        "hist = model.fit(X_train, y_train, batch_size = 57, epochs = 1000, validation_split=0.2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 491 samples, validate on 123 samples\n",
            "Epoch 1/1000\n",
            "491/491 [==============================] - 0s 594us/step - loss: 0.6782 - accuracy: 0.6477 - val_loss: 0.6772 - val_accuracy: 0.6504\n",
            "Epoch 2/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6761 - accuracy: 0.6477 - val_loss: 0.6751 - val_accuracy: 0.6504\n",
            "Epoch 3/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6740 - accuracy: 0.6477 - val_loss: 0.6733 - val_accuracy: 0.6504\n",
            "Epoch 4/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6724 - accuracy: 0.6477 - val_loss: 0.6716 - val_accuracy: 0.6504\n",
            "Epoch 5/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6709 - accuracy: 0.6477 - val_loss: 0.6702 - val_accuracy: 0.6504\n",
            "Epoch 6/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6695 - accuracy: 0.6477 - val_loss: 0.6688 - val_accuracy: 0.6504\n",
            "Epoch 7/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6683 - accuracy: 0.6477 - val_loss: 0.6675 - val_accuracy: 0.6504\n",
            "Epoch 8/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6672 - accuracy: 0.6477 - val_loss: 0.6664 - val_accuracy: 0.6504\n",
            "Epoch 9/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6661 - accuracy: 0.6477 - val_loss: 0.6653 - val_accuracy: 0.6504\n",
            "Epoch 10/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6651 - accuracy: 0.6477 - val_loss: 0.6643 - val_accuracy: 0.6504\n",
            "Epoch 11/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6643 - accuracy: 0.6477 - val_loss: 0.6634 - val_accuracy: 0.6504\n",
            "Epoch 12/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6634 - accuracy: 0.6477 - val_loss: 0.6626 - val_accuracy: 0.6504\n",
            "Epoch 13/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6627 - accuracy: 0.6477 - val_loss: 0.6619 - val_accuracy: 0.6504\n",
            "Epoch 14/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6621 - accuracy: 0.6477 - val_loss: 0.6613 - val_accuracy: 0.6504\n",
            "Epoch 15/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6615 - accuracy: 0.6477 - val_loss: 0.6608 - val_accuracy: 0.6504\n",
            "Epoch 16/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6611 - accuracy: 0.6477 - val_loss: 0.6604 - val_accuracy: 0.6504\n",
            "Epoch 17/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6607 - accuracy: 0.6477 - val_loss: 0.6600 - val_accuracy: 0.6504\n",
            "Epoch 18/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6603 - accuracy: 0.6477 - val_loss: 0.6594 - val_accuracy: 0.6504\n",
            "Epoch 19/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6599 - accuracy: 0.6477 - val_loss: 0.6590 - val_accuracy: 0.6504\n",
            "Epoch 20/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6594 - accuracy: 0.6477 - val_loss: 0.6587 - val_accuracy: 0.6504\n",
            "Epoch 21/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6591 - accuracy: 0.6477 - val_loss: 0.6584 - val_accuracy: 0.6504\n",
            "Epoch 22/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6588 - accuracy: 0.6477 - val_loss: 0.6580 - val_accuracy: 0.6504\n",
            "Epoch 23/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6585 - accuracy: 0.6477 - val_loss: 0.6577 - val_accuracy: 0.6504\n",
            "Epoch 24/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6582 - accuracy: 0.6477 - val_loss: 0.6573 - val_accuracy: 0.6504\n",
            "Epoch 25/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6579 - accuracy: 0.6477 - val_loss: 0.6571 - val_accuracy: 0.6504\n",
            "Epoch 26/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6576 - accuracy: 0.6477 - val_loss: 0.6568 - val_accuracy: 0.6504\n",
            "Epoch 27/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6574 - accuracy: 0.6477 - val_loss: 0.6566 - val_accuracy: 0.6504\n",
            "Epoch 28/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6572 - accuracy: 0.6477 - val_loss: 0.6564 - val_accuracy: 0.6504\n",
            "Epoch 29/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6570 - accuracy: 0.6477 - val_loss: 0.6562 - val_accuracy: 0.6504\n",
            "Epoch 30/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6568 - accuracy: 0.6477 - val_loss: 0.6560 - val_accuracy: 0.6504\n",
            "Epoch 31/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6566 - accuracy: 0.6477 - val_loss: 0.6558 - val_accuracy: 0.6504\n",
            "Epoch 32/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6564 - accuracy: 0.6477 - val_loss: 0.6555 - val_accuracy: 0.6504\n",
            "Epoch 33/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6562 - accuracy: 0.6477 - val_loss: 0.6554 - val_accuracy: 0.6504\n",
            "Epoch 34/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6561 - accuracy: 0.6477 - val_loss: 0.6552 - val_accuracy: 0.6504\n",
            "Epoch 35/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6558 - accuracy: 0.6477 - val_loss: 0.6550 - val_accuracy: 0.6504\n",
            "Epoch 36/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6556 - accuracy: 0.6477 - val_loss: 0.6548 - val_accuracy: 0.6504\n",
            "Epoch 37/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6555 - accuracy: 0.6477 - val_loss: 0.6547 - val_accuracy: 0.6504\n",
            "Epoch 38/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6553 - accuracy: 0.6477 - val_loss: 0.6545 - val_accuracy: 0.6504\n",
            "Epoch 39/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6552 - accuracy: 0.6477 - val_loss: 0.6544 - val_accuracy: 0.6504\n",
            "Epoch 40/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6550 - accuracy: 0.6477 - val_loss: 0.6542 - val_accuracy: 0.6504\n",
            "Epoch 41/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6549 - accuracy: 0.6477 - val_loss: 0.6541 - val_accuracy: 0.6504\n",
            "Epoch 42/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6547 - accuracy: 0.6477 - val_loss: 0.6539 - val_accuracy: 0.6504\n",
            "Epoch 43/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6545 - accuracy: 0.6477 - val_loss: 0.6538 - val_accuracy: 0.6504\n",
            "Epoch 44/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6544 - accuracy: 0.6477 - val_loss: 0.6537 - val_accuracy: 0.6504\n",
            "Epoch 45/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6543 - accuracy: 0.6477 - val_loss: 0.6535 - val_accuracy: 0.6504\n",
            "Epoch 46/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6540 - accuracy: 0.6477 - val_loss: 0.6534 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6539 - accuracy: 0.6477 - val_loss: 0.6532 - val_accuracy: 0.6504\n",
            "Epoch 48/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6537 - accuracy: 0.6477 - val_loss: 0.6531 - val_accuracy: 0.6504\n",
            "Epoch 49/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6536 - accuracy: 0.6477 - val_loss: 0.6530 - val_accuracy: 0.6504\n",
            "Epoch 50/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6535 - accuracy: 0.6477 - val_loss: 0.6529 - val_accuracy: 0.6504\n",
            "Epoch 51/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6533 - accuracy: 0.6477 - val_loss: 0.6527 - val_accuracy: 0.6504\n",
            "Epoch 52/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6532 - accuracy: 0.6477 - val_loss: 0.6526 - val_accuracy: 0.6504\n",
            "Epoch 53/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6530 - accuracy: 0.6477 - val_loss: 0.6524 - val_accuracy: 0.6504\n",
            "Epoch 54/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6528 - accuracy: 0.6477 - val_loss: 0.6523 - val_accuracy: 0.6504\n",
            "Epoch 55/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6527 - accuracy: 0.6477 - val_loss: 0.6522 - val_accuracy: 0.6504\n",
            "Epoch 56/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6525 - accuracy: 0.6477 - val_loss: 0.6520 - val_accuracy: 0.6504\n",
            "Epoch 57/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6524 - accuracy: 0.6477 - val_loss: 0.6519 - val_accuracy: 0.6504\n",
            "Epoch 58/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6523 - accuracy: 0.6477 - val_loss: 0.6517 - val_accuracy: 0.6504\n",
            "Epoch 59/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6521 - accuracy: 0.6477 - val_loss: 0.6516 - val_accuracy: 0.6504\n",
            "Epoch 60/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6520 - accuracy: 0.6477 - val_loss: 0.6515 - val_accuracy: 0.6504\n",
            "Epoch 61/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6518 - accuracy: 0.6477 - val_loss: 0.6513 - val_accuracy: 0.6504\n",
            "Epoch 62/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6516 - accuracy: 0.6477 - val_loss: 0.6512 - val_accuracy: 0.6504\n",
            "Epoch 63/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6514 - accuracy: 0.6477 - val_loss: 0.6511 - val_accuracy: 0.6504\n",
            "Epoch 64/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6513 - accuracy: 0.6477 - val_loss: 0.6509 - val_accuracy: 0.6504\n",
            "Epoch 65/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6511 - accuracy: 0.6477 - val_loss: 0.6508 - val_accuracy: 0.6504\n",
            "Epoch 66/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6510 - accuracy: 0.6477 - val_loss: 0.6506 - val_accuracy: 0.6504\n",
            "Epoch 67/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6508 - accuracy: 0.6477 - val_loss: 0.6505 - val_accuracy: 0.6504\n",
            "Epoch 68/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6506 - accuracy: 0.6477 - val_loss: 0.6504 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6505 - accuracy: 0.6477 - val_loss: 0.6502 - val_accuracy: 0.6504\n",
            "Epoch 70/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6503 - accuracy: 0.6477 - val_loss: 0.6501 - val_accuracy: 0.6504\n",
            "Epoch 71/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6502 - accuracy: 0.6477 - val_loss: 0.6499 - val_accuracy: 0.6504\n",
            "Epoch 72/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6500 - accuracy: 0.6477 - val_loss: 0.6498 - val_accuracy: 0.6504\n",
            "Epoch 73/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6498 - accuracy: 0.6477 - val_loss: 0.6496 - val_accuracy: 0.6504\n",
            "Epoch 74/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.6497 - accuracy: 0.6477 - val_loss: 0.6495 - val_accuracy: 0.6504\n",
            "Epoch 75/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6494 - accuracy: 0.6477 - val_loss: 0.6493 - val_accuracy: 0.6504\n",
            "Epoch 76/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6494 - accuracy: 0.6477 - val_loss: 0.6492 - val_accuracy: 0.6504\n",
            "Epoch 77/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6492 - accuracy: 0.6477 - val_loss: 0.6491 - val_accuracy: 0.6504\n",
            "Epoch 78/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6490 - accuracy: 0.6477 - val_loss: 0.6489 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6488 - accuracy: 0.6477 - val_loss: 0.6488 - val_accuracy: 0.6504\n",
            "Epoch 80/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6487 - accuracy: 0.6477 - val_loss: 0.6487 - val_accuracy: 0.6504\n",
            "Epoch 81/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6485 - accuracy: 0.6477 - val_loss: 0.6485 - val_accuracy: 0.6504\n",
            "Epoch 82/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6484 - accuracy: 0.6477 - val_loss: 0.6484 - val_accuracy: 0.6504\n",
            "Epoch 83/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6482 - accuracy: 0.6477 - val_loss: 0.6482 - val_accuracy: 0.6504\n",
            "Epoch 84/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6480 - accuracy: 0.6477 - val_loss: 0.6481 - val_accuracy: 0.6504\n",
            "Epoch 85/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6479 - accuracy: 0.6477 - val_loss: 0.6479 - val_accuracy: 0.6504\n",
            "Epoch 86/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6477 - accuracy: 0.6477 - val_loss: 0.6478 - val_accuracy: 0.6504\n",
            "Epoch 87/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6475 - accuracy: 0.6477 - val_loss: 0.6476 - val_accuracy: 0.6504\n",
            "Epoch 88/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6474 - accuracy: 0.6477 - val_loss: 0.6475 - val_accuracy: 0.6504\n",
            "Epoch 89/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6472 - accuracy: 0.6477 - val_loss: 0.6473 - val_accuracy: 0.6504\n",
            "Epoch 90/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6471 - accuracy: 0.6477 - val_loss: 0.6471 - val_accuracy: 0.6504\n",
            "Epoch 91/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6469 - accuracy: 0.6477 - val_loss: 0.6470 - val_accuracy: 0.6504\n",
            "Epoch 92/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6468 - accuracy: 0.6477 - val_loss: 0.6468 - val_accuracy: 0.6504\n",
            "Epoch 93/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6466 - accuracy: 0.6477 - val_loss: 0.6467 - val_accuracy: 0.6504\n",
            "Epoch 94/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6463 - accuracy: 0.6477 - val_loss: 0.6465 - val_accuracy: 0.6504\n",
            "Epoch 95/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6462 - accuracy: 0.6477 - val_loss: 0.6464 - val_accuracy: 0.6504\n",
            "Epoch 96/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6460 - accuracy: 0.6477 - val_loss: 0.6462 - val_accuracy: 0.6504\n",
            "Epoch 97/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6459 - accuracy: 0.6477 - val_loss: 0.6460 - val_accuracy: 0.6504\n",
            "Epoch 98/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6457 - accuracy: 0.6477 - val_loss: 0.6459 - val_accuracy: 0.6504\n",
            "Epoch 99/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6455 - accuracy: 0.6477 - val_loss: 0.6457 - val_accuracy: 0.6504\n",
            "Epoch 100/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6453 - accuracy: 0.6477 - val_loss: 0.6455 - val_accuracy: 0.6504\n",
            "Epoch 101/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6452 - accuracy: 0.6477 - val_loss: 0.6453 - val_accuracy: 0.6504\n",
            "Epoch 102/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6450 - accuracy: 0.6477 - val_loss: 0.6452 - val_accuracy: 0.6504\n",
            "Epoch 103/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6448 - accuracy: 0.6477 - val_loss: 0.6450 - val_accuracy: 0.6504\n",
            "Epoch 104/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6446 - accuracy: 0.6477 - val_loss: 0.6448 - val_accuracy: 0.6504\n",
            "Epoch 105/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6445 - accuracy: 0.6477 - val_loss: 0.6446 - val_accuracy: 0.6504\n",
            "Epoch 106/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6443 - accuracy: 0.6477 - val_loss: 0.6445 - val_accuracy: 0.6504\n",
            "Epoch 107/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6441 - accuracy: 0.6477 - val_loss: 0.6443 - val_accuracy: 0.6504\n",
            "Epoch 108/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6439 - accuracy: 0.6477 - val_loss: 0.6441 - val_accuracy: 0.6504\n",
            "Epoch 109/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6437 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
            "Epoch 110/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6436 - accuracy: 0.6477 - val_loss: 0.6438 - val_accuracy: 0.6504\n",
            "Epoch 111/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6434 - accuracy: 0.6477 - val_loss: 0.6437 - val_accuracy: 0.6504\n",
            "Epoch 112/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6432 - accuracy: 0.6477 - val_loss: 0.6435 - val_accuracy: 0.6504\n",
            "Epoch 113/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6430 - accuracy: 0.6477 - val_loss: 0.6433 - val_accuracy: 0.6504\n",
            "Epoch 114/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6428 - accuracy: 0.6477 - val_loss: 0.6432 - val_accuracy: 0.6504\n",
            "Epoch 115/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6426 - accuracy: 0.6477 - val_loss: 0.6430 - val_accuracy: 0.6504\n",
            "Epoch 116/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6424 - accuracy: 0.6477 - val_loss: 0.6428 - val_accuracy: 0.6504\n",
            "Epoch 117/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6422 - accuracy: 0.6477 - val_loss: 0.6426 - val_accuracy: 0.6504\n",
            "Epoch 118/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.6420 - accuracy: 0.6477 - val_loss: 0.6425 - val_accuracy: 0.6504\n",
            "Epoch 119/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6418 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.6504\n",
            "Epoch 120/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6416 - accuracy: 0.6477 - val_loss: 0.6422 - val_accuracy: 0.6504\n",
            "Epoch 121/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6414 - accuracy: 0.6477 - val_loss: 0.6420 - val_accuracy: 0.6504\n",
            "Epoch 122/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6412 - accuracy: 0.6477 - val_loss: 0.6419 - val_accuracy: 0.6504\n",
            "Epoch 123/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6411 - accuracy: 0.6477 - val_loss: 0.6417 - val_accuracy: 0.6504\n",
            "Epoch 124/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6408 - accuracy: 0.6477 - val_loss: 0.6415 - val_accuracy: 0.6504\n",
            "Epoch 125/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6407 - accuracy: 0.6477 - val_loss: 0.6414 - val_accuracy: 0.6504\n",
            "Epoch 126/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6404 - accuracy: 0.6477 - val_loss: 0.6412 - val_accuracy: 0.6504\n",
            "Epoch 127/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6402 - accuracy: 0.6477 - val_loss: 0.6410 - val_accuracy: 0.6504\n",
            "Epoch 128/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6400 - accuracy: 0.6477 - val_loss: 0.6409 - val_accuracy: 0.6504\n",
            "Epoch 129/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6399 - accuracy: 0.6477 - val_loss: 0.6407 - val_accuracy: 0.6504\n",
            "Epoch 130/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6397 - accuracy: 0.6477 - val_loss: 0.6405 - val_accuracy: 0.6504\n",
            "Epoch 131/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6394 - accuracy: 0.6477 - val_loss: 0.6403 - val_accuracy: 0.6504\n",
            "Epoch 132/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6402 - val_accuracy: 0.6504\n",
            "Epoch 133/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6391 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
            "Epoch 134/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6389 - accuracy: 0.6477 - val_loss: 0.6398 - val_accuracy: 0.6504\n",
            "Epoch 135/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6387 - accuracy: 0.6477 - val_loss: 0.6397 - val_accuracy: 0.6504\n",
            "Epoch 136/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6386 - accuracy: 0.6477 - val_loss: 0.6395 - val_accuracy: 0.6504\n",
            "Epoch 137/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6383 - accuracy: 0.6477 - val_loss: 0.6394 - val_accuracy: 0.6504\n",
            "Epoch 138/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6381 - accuracy: 0.6477 - val_loss: 0.6392 - val_accuracy: 0.6504\n",
            "Epoch 139/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6380 - accuracy: 0.6477 - val_loss: 0.6390 - val_accuracy: 0.6504\n",
            "Epoch 140/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6377 - accuracy: 0.6477 - val_loss: 0.6389 - val_accuracy: 0.6504\n",
            "Epoch 141/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6376 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
            "Epoch 142/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6374 - accuracy: 0.6477 - val_loss: 0.6385 - val_accuracy: 0.6504\n",
            "Epoch 143/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6371 - accuracy: 0.6477 - val_loss: 0.6384 - val_accuracy: 0.6504\n",
            "Epoch 144/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6369 - accuracy: 0.6477 - val_loss: 0.6382 - val_accuracy: 0.6504\n",
            "Epoch 145/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6368 - accuracy: 0.6477 - val_loss: 0.6380 - val_accuracy: 0.6504\n",
            "Epoch 146/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6366 - accuracy: 0.6477 - val_loss: 0.6378 - val_accuracy: 0.6504\n",
            "Epoch 147/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6364 - accuracy: 0.6477 - val_loss: 0.6377 - val_accuracy: 0.6504\n",
            "Epoch 148/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6362 - accuracy: 0.6477 - val_loss: 0.6375 - val_accuracy: 0.6504\n",
            "Epoch 149/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6373 - val_accuracy: 0.6504\n",
            "Epoch 150/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6357 - accuracy: 0.6477 - val_loss: 0.6371 - val_accuracy: 0.6504\n",
            "Epoch 151/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6356 - accuracy: 0.6477 - val_loss: 0.6370 - val_accuracy: 0.6504\n",
            "Epoch 152/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6353 - accuracy: 0.6477 - val_loss: 0.6368 - val_accuracy: 0.6504\n",
            "Epoch 153/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6352 - accuracy: 0.6477 - val_loss: 0.6366 - val_accuracy: 0.6504\n",
            "Epoch 154/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6350 - accuracy: 0.6477 - val_loss: 0.6364 - val_accuracy: 0.6504\n",
            "Epoch 155/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6348 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
            "Epoch 156/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6346 - accuracy: 0.6477 - val_loss: 0.6361 - val_accuracy: 0.6504\n",
            "Epoch 157/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6344 - accuracy: 0.6477 - val_loss: 0.6359 - val_accuracy: 0.6504\n",
            "Epoch 158/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6342 - accuracy: 0.6477 - val_loss: 0.6357 - val_accuracy: 0.6504\n",
            "Epoch 159/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6340 - accuracy: 0.6477 - val_loss: 0.6355 - val_accuracy: 0.6504\n",
            "Epoch 160/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6338 - accuracy: 0.6477 - val_loss: 0.6353 - val_accuracy: 0.6504\n",
            "Epoch 161/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6336 - accuracy: 0.6477 - val_loss: 0.6352 - val_accuracy: 0.6504\n",
            "Epoch 162/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6335 - accuracy: 0.6477 - val_loss: 0.6350 - val_accuracy: 0.6504\n",
            "Epoch 163/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6332 - accuracy: 0.6477 - val_loss: 0.6348 - val_accuracy: 0.6504\n",
            "Epoch 164/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6330 - accuracy: 0.6477 - val_loss: 0.6346 - val_accuracy: 0.6504\n",
            "Epoch 165/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6328 - accuracy: 0.6477 - val_loss: 0.6344 - val_accuracy: 0.6504\n",
            "Epoch 166/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6326 - accuracy: 0.6477 - val_loss: 0.6342 - val_accuracy: 0.6504\n",
            "Epoch 167/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6323 - accuracy: 0.6477 - val_loss: 0.6340 - val_accuracy: 0.6504\n",
            "Epoch 168/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6321 - accuracy: 0.6477 - val_loss: 0.6339 - val_accuracy: 0.6504\n",
            "Epoch 169/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6319 - accuracy: 0.6477 - val_loss: 0.6337 - val_accuracy: 0.6504\n",
            "Epoch 170/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6317 - accuracy: 0.6477 - val_loss: 0.6335 - val_accuracy: 0.6504\n",
            "Epoch 171/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6316 - accuracy: 0.6477 - val_loss: 0.6333 - val_accuracy: 0.6504\n",
            "Epoch 172/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6313 - accuracy: 0.6477 - val_loss: 0.6331 - val_accuracy: 0.6504\n",
            "Epoch 173/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6312 - accuracy: 0.6477 - val_loss: 0.6330 - val_accuracy: 0.6504\n",
            "Epoch 174/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6308 - accuracy: 0.6477 - val_loss: 0.6328 - val_accuracy: 0.6504\n",
            "Epoch 175/1000\n",
            "491/491 [==============================] - 0s 53us/step - loss: 0.6306 - accuracy: 0.6477 - val_loss: 0.6326 - val_accuracy: 0.6504\n",
            "Epoch 176/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6304 - accuracy: 0.6477 - val_loss: 0.6324 - val_accuracy: 0.6504\n",
            "Epoch 177/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6303 - accuracy: 0.6477 - val_loss: 0.6322 - val_accuracy: 0.6504\n",
            "Epoch 178/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6299 - accuracy: 0.6477 - val_loss: 0.6320 - val_accuracy: 0.6504\n",
            "Epoch 179/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6297 - accuracy: 0.6477 - val_loss: 0.6318 - val_accuracy: 0.6504\n",
            "Epoch 180/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6295 - accuracy: 0.6477 - val_loss: 0.6316 - val_accuracy: 0.6504\n",
            "Epoch 181/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6292 - accuracy: 0.6477 - val_loss: 0.6314 - val_accuracy: 0.6504\n",
            "Epoch 182/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6290 - accuracy: 0.6477 - val_loss: 0.6313 - val_accuracy: 0.6504\n",
            "Epoch 183/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6288 - accuracy: 0.6477 - val_loss: 0.6311 - val_accuracy: 0.6504\n",
            "Epoch 184/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6287 - accuracy: 0.6477 - val_loss: 0.6309 - val_accuracy: 0.6504\n",
            "Epoch 185/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6284 - accuracy: 0.6477 - val_loss: 0.6307 - val_accuracy: 0.6504\n",
            "Epoch 186/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6282 - accuracy: 0.6477 - val_loss: 0.6305 - val_accuracy: 0.6504\n",
            "Epoch 187/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6279 - accuracy: 0.6477 - val_loss: 0.6303 - val_accuracy: 0.6504\n",
            "Epoch 188/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6277 - accuracy: 0.6477 - val_loss: 0.6301 - val_accuracy: 0.6504\n",
            "Epoch 189/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6274 - accuracy: 0.6477 - val_loss: 0.6299 - val_accuracy: 0.6504\n",
            "Epoch 190/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6272 - accuracy: 0.6477 - val_loss: 0.6297 - val_accuracy: 0.6504\n",
            "Epoch 191/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6269 - accuracy: 0.6477 - val_loss: 0.6296 - val_accuracy: 0.6504\n",
            "Epoch 192/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6267 - accuracy: 0.6477 - val_loss: 0.6294 - val_accuracy: 0.6504\n",
            "Epoch 193/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6264 - accuracy: 0.6477 - val_loss: 0.6292 - val_accuracy: 0.6504\n",
            "Epoch 194/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6290 - val_accuracy: 0.6504\n",
            "Epoch 195/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6260 - accuracy: 0.6477 - val_loss: 0.6288 - val_accuracy: 0.6504\n",
            "Epoch 196/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6257 - accuracy: 0.6477 - val_loss: 0.6286 - val_accuracy: 0.6504\n",
            "Epoch 197/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6255 - accuracy: 0.6477 - val_loss: 0.6284 - val_accuracy: 0.6504\n",
            "Epoch 198/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6252 - accuracy: 0.6477 - val_loss: 0.6282 - val_accuracy: 0.6504\n",
            "Epoch 199/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6250 - accuracy: 0.6477 - val_loss: 0.6280 - val_accuracy: 0.6504\n",
            "Epoch 200/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.6278 - val_accuracy: 0.6504\n",
            "Epoch 201/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6245 - accuracy: 0.6477 - val_loss: 0.6276 - val_accuracy: 0.6504\n",
            "Epoch 202/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6244 - accuracy: 0.6477 - val_loss: 0.6274 - val_accuracy: 0.6504\n",
            "Epoch 203/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6241 - accuracy: 0.6477 - val_loss: 0.6272 - val_accuracy: 0.6504\n",
            "Epoch 204/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6238 - accuracy: 0.6477 - val_loss: 0.6269 - val_accuracy: 0.6504\n",
            "Epoch 205/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6236 - accuracy: 0.6477 - val_loss: 0.6267 - val_accuracy: 0.6504\n",
            "Epoch 206/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6232 - accuracy: 0.6477 - val_loss: 0.6265 - val_accuracy: 0.6504\n",
            "Epoch 207/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6230 - accuracy: 0.6477 - val_loss: 0.6263 - val_accuracy: 0.6504\n",
            "Epoch 208/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6227 - accuracy: 0.6477 - val_loss: 0.6261 - val_accuracy: 0.6504\n",
            "Epoch 209/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6226 - accuracy: 0.6477 - val_loss: 0.6258 - val_accuracy: 0.6504\n",
            "Epoch 210/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6222 - accuracy: 0.6477 - val_loss: 0.6256 - val_accuracy: 0.6504\n",
            "Epoch 211/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6220 - accuracy: 0.6477 - val_loss: 0.6254 - val_accuracy: 0.6504\n",
            "Epoch 212/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6217 - accuracy: 0.6477 - val_loss: 0.6252 - val_accuracy: 0.6504\n",
            "Epoch 213/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6215 - accuracy: 0.6477 - val_loss: 0.6249 - val_accuracy: 0.6504\n",
            "Epoch 214/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6212 - accuracy: 0.6477 - val_loss: 0.6247 - val_accuracy: 0.6504\n",
            "Epoch 215/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6210 - accuracy: 0.6477 - val_loss: 0.6245 - val_accuracy: 0.6504\n",
            "Epoch 216/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6206 - accuracy: 0.6477 - val_loss: 0.6242 - val_accuracy: 0.6504\n",
            "Epoch 217/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6204 - accuracy: 0.6477 - val_loss: 0.6240 - val_accuracy: 0.6504\n",
            "Epoch 218/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6200 - accuracy: 0.6477 - val_loss: 0.6238 - val_accuracy: 0.6504\n",
            "Epoch 219/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6199 - accuracy: 0.6477 - val_loss: 0.6235 - val_accuracy: 0.6504\n",
            "Epoch 220/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6196 - accuracy: 0.6477 - val_loss: 0.6233 - val_accuracy: 0.6504\n",
            "Epoch 221/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6193 - accuracy: 0.6477 - val_loss: 0.6231 - val_accuracy: 0.6504\n",
            "Epoch 222/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6190 - accuracy: 0.6477 - val_loss: 0.6228 - val_accuracy: 0.6504\n",
            "Epoch 223/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6187 - accuracy: 0.6477 - val_loss: 0.6226 - val_accuracy: 0.6504\n",
            "Epoch 224/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6184 - accuracy: 0.6477 - val_loss: 0.6223 - val_accuracy: 0.6504\n",
            "Epoch 225/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6181 - accuracy: 0.6477 - val_loss: 0.6221 - val_accuracy: 0.6504\n",
            "Epoch 226/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6178 - accuracy: 0.6477 - val_loss: 0.6218 - val_accuracy: 0.6504\n",
            "Epoch 227/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6175 - accuracy: 0.6477 - val_loss: 0.6216 - val_accuracy: 0.6504\n",
            "Epoch 228/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6172 - accuracy: 0.6477 - val_loss: 0.6213 - val_accuracy: 0.6504\n",
            "Epoch 229/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6169 - accuracy: 0.6477 - val_loss: 0.6211 - val_accuracy: 0.6504\n",
            "Epoch 230/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6166 - accuracy: 0.6477 - val_loss: 0.6208 - val_accuracy: 0.6504\n",
            "Epoch 231/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6163 - accuracy: 0.6477 - val_loss: 0.6206 - val_accuracy: 0.6504\n",
            "Epoch 232/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6160 - accuracy: 0.6477 - val_loss: 0.6203 - val_accuracy: 0.6504\n",
            "Epoch 233/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6159 - accuracy: 0.6477 - val_loss: 0.6200 - val_accuracy: 0.6504\n",
            "Epoch 234/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6155 - accuracy: 0.6477 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
            "Epoch 235/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6152 - accuracy: 0.6477 - val_loss: 0.6195 - val_accuracy: 0.6504\n",
            "Epoch 236/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6149 - accuracy: 0.6477 - val_loss: 0.6193 - val_accuracy: 0.6504\n",
            "Epoch 237/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6145 - accuracy: 0.6477 - val_loss: 0.6190 - val_accuracy: 0.6504\n",
            "Epoch 238/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6142 - accuracy: 0.6477 - val_loss: 0.6187 - val_accuracy: 0.6504\n",
            "Epoch 239/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6140 - accuracy: 0.6477 - val_loss: 0.6184 - val_accuracy: 0.6504\n",
            "Epoch 240/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6136 - accuracy: 0.6477 - val_loss: 0.6182 - val_accuracy: 0.6504\n",
            "Epoch 241/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6133 - accuracy: 0.6477 - val_loss: 0.6179 - val_accuracy: 0.6504\n",
            "Epoch 242/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6129 - accuracy: 0.6477 - val_loss: 0.6176 - val_accuracy: 0.6504\n",
            "Epoch 243/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6126 - accuracy: 0.6477 - val_loss: 0.6173 - val_accuracy: 0.6504\n",
            "Epoch 244/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6123 - accuracy: 0.6477 - val_loss: 0.6170 - val_accuracy: 0.6504\n",
            "Epoch 245/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6120 - accuracy: 0.6477 - val_loss: 0.6167 - val_accuracy: 0.6504\n",
            "Epoch 246/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6117 - accuracy: 0.6477 - val_loss: 0.6164 - val_accuracy: 0.6504\n",
            "Epoch 247/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6113 - accuracy: 0.6477 - val_loss: 0.6161 - val_accuracy: 0.6504\n",
            "Epoch 248/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6110 - accuracy: 0.6477 - val_loss: 0.6158 - val_accuracy: 0.6504\n",
            "Epoch 249/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6106 - accuracy: 0.6477 - val_loss: 0.6155 - val_accuracy: 0.6504\n",
            "Epoch 250/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6103 - accuracy: 0.6477 - val_loss: 0.6152 - val_accuracy: 0.6504\n",
            "Epoch 251/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6100 - accuracy: 0.6477 - val_loss: 0.6149 - val_accuracy: 0.6504\n",
            "Epoch 252/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6097 - accuracy: 0.6477 - val_loss: 0.6146 - val_accuracy: 0.6504\n",
            "Epoch 253/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6093 - accuracy: 0.6477 - val_loss: 0.6143 - val_accuracy: 0.6504\n",
            "Epoch 254/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6089 - accuracy: 0.6477 - val_loss: 0.6140 - val_accuracy: 0.6504\n",
            "Epoch 255/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6085 - accuracy: 0.6477 - val_loss: 0.6137 - val_accuracy: 0.6504\n",
            "Epoch 256/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6082 - accuracy: 0.6477 - val_loss: 0.6134 - val_accuracy: 0.6504\n",
            "Epoch 257/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6077 - accuracy: 0.6477 - val_loss: 0.6131 - val_accuracy: 0.6504\n",
            "Epoch 258/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6073 - accuracy: 0.6477 - val_loss: 0.6128 - val_accuracy: 0.6504\n",
            "Epoch 259/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6071 - accuracy: 0.6477 - val_loss: 0.6125 - val_accuracy: 0.6504\n",
            "Epoch 260/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6065 - accuracy: 0.6477 - val_loss: 0.6122 - val_accuracy: 0.6504\n",
            "Epoch 261/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6062 - accuracy: 0.6477 - val_loss: 0.6119 - val_accuracy: 0.6504\n",
            "Epoch 262/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6057 - accuracy: 0.6477 - val_loss: 0.6115 - val_accuracy: 0.6504\n",
            "Epoch 263/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6054 - accuracy: 0.6477 - val_loss: 0.6112 - val_accuracy: 0.6504\n",
            "Epoch 264/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6051 - accuracy: 0.6477 - val_loss: 0.6109 - val_accuracy: 0.6504\n",
            "Epoch 265/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6046 - accuracy: 0.6477 - val_loss: 0.6105 - val_accuracy: 0.6504\n",
            "Epoch 266/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.6041 - accuracy: 0.6477 - val_loss: 0.6102 - val_accuracy: 0.6504\n",
            "Epoch 267/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6039 - accuracy: 0.6477 - val_loss: 0.6098 - val_accuracy: 0.6504\n",
            "Epoch 268/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6034 - accuracy: 0.6477 - val_loss: 0.6095 - val_accuracy: 0.6504\n",
            "Epoch 269/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6028 - accuracy: 0.6477 - val_loss: 0.6091 - val_accuracy: 0.6504\n",
            "Epoch 270/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6024 - accuracy: 0.6477 - val_loss: 0.6088 - val_accuracy: 0.6504\n",
            "Epoch 271/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6019 - accuracy: 0.6477 - val_loss: 0.6084 - val_accuracy: 0.6504\n",
            "Epoch 272/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6018 - accuracy: 0.6477 - val_loss: 0.6080 - val_accuracy: 0.6504\n",
            "Epoch 273/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6009 - accuracy: 0.6477 - val_loss: 0.6076 - val_accuracy: 0.6504\n",
            "Epoch 274/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6005 - accuracy: 0.6477 - val_loss: 0.6073 - val_accuracy: 0.6504\n",
            "Epoch 275/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6002 - accuracy: 0.6477 - val_loss: 0.6069 - val_accuracy: 0.6504\n",
            "Epoch 276/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5995 - accuracy: 0.6477 - val_loss: 0.6065 - val_accuracy: 0.6504\n",
            "Epoch 277/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5991 - accuracy: 0.6477 - val_loss: 0.6062 - val_accuracy: 0.6504\n",
            "Epoch 278/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.5988 - accuracy: 0.6477 - val_loss: 0.6058 - val_accuracy: 0.6504\n",
            "Epoch 279/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5982 - accuracy: 0.6477 - val_loss: 0.6054 - val_accuracy: 0.6504\n",
            "Epoch 280/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5976 - accuracy: 0.6477 - val_loss: 0.6050 - val_accuracy: 0.6504\n",
            "Epoch 281/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5971 - accuracy: 0.6477 - val_loss: 0.6046 - val_accuracy: 0.6504\n",
            "Epoch 282/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5967 - accuracy: 0.6477 - val_loss: 0.6042 - val_accuracy: 0.6504\n",
            "Epoch 283/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5963 - accuracy: 0.6477 - val_loss: 0.6038 - val_accuracy: 0.6504\n",
            "Epoch 284/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5956 - accuracy: 0.6477 - val_loss: 0.6034 - val_accuracy: 0.6504\n",
            "Epoch 285/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5950 - accuracy: 0.6477 - val_loss: 0.6029 - val_accuracy: 0.6504\n",
            "Epoch 286/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5946 - accuracy: 0.6477 - val_loss: 0.6025 - val_accuracy: 0.6504\n",
            "Epoch 287/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5939 - accuracy: 0.6477 - val_loss: 0.6021 - val_accuracy: 0.6504\n",
            "Epoch 288/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5934 - accuracy: 0.6477 - val_loss: 0.6016 - val_accuracy: 0.6504\n",
            "Epoch 289/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5928 - accuracy: 0.6477 - val_loss: 0.6012 - val_accuracy: 0.6504\n",
            "Epoch 290/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5924 - accuracy: 0.6477 - val_loss: 0.6008 - val_accuracy: 0.6504\n",
            "Epoch 291/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5918 - accuracy: 0.6477 - val_loss: 0.6004 - val_accuracy: 0.6504\n",
            "Epoch 292/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5913 - accuracy: 0.6477 - val_loss: 0.6000 - val_accuracy: 0.6504\n",
            "Epoch 293/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5907 - accuracy: 0.6477 - val_loss: 0.5995 - val_accuracy: 0.6504\n",
            "Epoch 294/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5900 - accuracy: 0.6477 - val_loss: 0.5991 - val_accuracy: 0.6504\n",
            "Epoch 295/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5896 - accuracy: 0.6477 - val_loss: 0.5987 - val_accuracy: 0.6504\n",
            "Epoch 296/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5889 - accuracy: 0.6497 - val_loss: 0.5982 - val_accuracy: 0.6585\n",
            "Epoch 297/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5883 - accuracy: 0.6517 - val_loss: 0.5977 - val_accuracy: 0.6585\n",
            "Epoch 298/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5879 - accuracy: 0.6538 - val_loss: 0.5973 - val_accuracy: 0.6585\n",
            "Epoch 299/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5873 - accuracy: 0.6538 - val_loss: 0.5968 - val_accuracy: 0.6585\n",
            "Epoch 300/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5868 - accuracy: 0.6538 - val_loss: 0.5964 - val_accuracy: 0.6585\n",
            "Epoch 301/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5861 - accuracy: 0.6558 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
            "Epoch 302/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5856 - accuracy: 0.6558 - val_loss: 0.5954 - val_accuracy: 0.6667\n",
            "Epoch 303/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5851 - accuracy: 0.6578 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
            "Epoch 304/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5846 - accuracy: 0.6578 - val_loss: 0.5945 - val_accuracy: 0.6667\n",
            "Epoch 305/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5840 - accuracy: 0.6578 - val_loss: 0.5941 - val_accuracy: 0.6667\n",
            "Epoch 306/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5834 - accuracy: 0.6578 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
            "Epoch 307/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5829 - accuracy: 0.6599 - val_loss: 0.5931 - val_accuracy: 0.6667\n",
            "Epoch 308/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5824 - accuracy: 0.6599 - val_loss: 0.5926 - val_accuracy: 0.6667\n",
            "Epoch 309/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5819 - accuracy: 0.6619 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
            "Epoch 310/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5814 - accuracy: 0.6660 - val_loss: 0.5917 - val_accuracy: 0.6585\n",
            "Epoch 311/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5809 - accuracy: 0.6660 - val_loss: 0.5912 - val_accuracy: 0.6585\n",
            "Epoch 312/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5802 - accuracy: 0.6660 - val_loss: 0.5908 - val_accuracy: 0.6504\n",
            "Epoch 313/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5796 - accuracy: 0.6599 - val_loss: 0.5903 - val_accuracy: 0.6504\n",
            "Epoch 314/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5792 - accuracy: 0.6619 - val_loss: 0.5898 - val_accuracy: 0.6504\n",
            "Epoch 315/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5786 - accuracy: 0.6599 - val_loss: 0.5894 - val_accuracy: 0.6423\n",
            "Epoch 316/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5781 - accuracy: 0.6619 - val_loss: 0.5889 - val_accuracy: 0.6423\n",
            "Epoch 317/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5775 - accuracy: 0.6701 - val_loss: 0.5884 - val_accuracy: 0.6504\n",
            "Epoch 318/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5770 - accuracy: 0.6701 - val_loss: 0.5880 - val_accuracy: 0.6585\n",
            "Epoch 319/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5764 - accuracy: 0.6701 - val_loss: 0.5875 - val_accuracy: 0.6585\n",
            "Epoch 320/1000\n",
            "491/491 [==============================] - 0s 53us/step - loss: 0.5758 - accuracy: 0.6680 - val_loss: 0.5870 - val_accuracy: 0.6667\n",
            "Epoch 321/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5753 - accuracy: 0.6721 - val_loss: 0.5865 - val_accuracy: 0.6667\n",
            "Epoch 322/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5748 - accuracy: 0.6782 - val_loss: 0.5861 - val_accuracy: 0.6667\n",
            "Epoch 323/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5742 - accuracy: 0.6762 - val_loss: 0.5856 - val_accuracy: 0.6667\n",
            "Epoch 324/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5736 - accuracy: 0.6782 - val_loss: 0.5851 - val_accuracy: 0.6667\n",
            "Epoch 325/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5731 - accuracy: 0.6762 - val_loss: 0.5846 - val_accuracy: 0.6585\n",
            "Epoch 326/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5725 - accuracy: 0.6782 - val_loss: 0.5842 - val_accuracy: 0.6585\n",
            "Epoch 327/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5722 - accuracy: 0.6782 - val_loss: 0.5837 - val_accuracy: 0.6585\n",
            "Epoch 328/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5714 - accuracy: 0.6782 - val_loss: 0.5832 - val_accuracy: 0.6585\n",
            "Epoch 329/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5709 - accuracy: 0.6843 - val_loss: 0.5827 - val_accuracy: 0.6585\n",
            "Epoch 330/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5702 - accuracy: 0.6843 - val_loss: 0.5822 - val_accuracy: 0.6504\n",
            "Epoch 331/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5699 - accuracy: 0.6823 - val_loss: 0.5817 - val_accuracy: 0.6504\n",
            "Epoch 332/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5692 - accuracy: 0.6843 - val_loss: 0.5813 - val_accuracy: 0.6504\n",
            "Epoch 333/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5686 - accuracy: 0.6823 - val_loss: 0.5808 - val_accuracy: 0.6585\n",
            "Epoch 334/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5680 - accuracy: 0.6864 - val_loss: 0.5803 - val_accuracy: 0.6504\n",
            "Epoch 335/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5676 - accuracy: 0.6823 - val_loss: 0.5798 - val_accuracy: 0.6504\n",
            "Epoch 336/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5669 - accuracy: 0.6904 - val_loss: 0.5793 - val_accuracy: 0.6504\n",
            "Epoch 337/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5664 - accuracy: 0.6925 - val_loss: 0.5789 - val_accuracy: 0.6504\n",
            "Epoch 338/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5658 - accuracy: 0.6904 - val_loss: 0.5784 - val_accuracy: 0.6504\n",
            "Epoch 339/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5655 - accuracy: 0.6965 - val_loss: 0.5779 - val_accuracy: 0.6585\n",
            "Epoch 340/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5648 - accuracy: 0.6864 - val_loss: 0.5774 - val_accuracy: 0.6504\n",
            "Epoch 341/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5642 - accuracy: 0.6925 - val_loss: 0.5770 - val_accuracy: 0.6585\n",
            "Epoch 342/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5638 - accuracy: 0.6965 - val_loss: 0.5765 - val_accuracy: 0.6585\n",
            "Epoch 343/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5631 - accuracy: 0.6945 - val_loss: 0.5761 - val_accuracy: 0.6504\n",
            "Epoch 344/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5626 - accuracy: 0.6945 - val_loss: 0.5756 - val_accuracy: 0.6423\n",
            "Epoch 345/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5619 - accuracy: 0.6925 - val_loss: 0.5751 - val_accuracy: 0.6423\n",
            "Epoch 346/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5614 - accuracy: 0.6925 - val_loss: 0.5747 - val_accuracy: 0.6423\n",
            "Epoch 347/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5609 - accuracy: 0.6945 - val_loss: 0.5742 - val_accuracy: 0.6341\n",
            "Epoch 348/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5603 - accuracy: 0.6965 - val_loss: 0.5738 - val_accuracy: 0.6341\n",
            "Epoch 349/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5597 - accuracy: 0.6986 - val_loss: 0.5733 - val_accuracy: 0.6341\n",
            "Epoch 350/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5591 - accuracy: 0.7026 - val_loss: 0.5729 - val_accuracy: 0.6341\n",
            "Epoch 351/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5587 - accuracy: 0.7026 - val_loss: 0.5724 - val_accuracy: 0.6341\n",
            "Epoch 352/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5583 - accuracy: 0.6965 - val_loss: 0.5720 - val_accuracy: 0.6341\n",
            "Epoch 353/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5577 - accuracy: 0.7047 - val_loss: 0.5715 - val_accuracy: 0.6341\n",
            "Epoch 354/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5572 - accuracy: 0.6986 - val_loss: 0.5710 - val_accuracy: 0.6341\n",
            "Epoch 355/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5567 - accuracy: 0.7088 - val_loss: 0.5706 - val_accuracy: 0.6341\n",
            "Epoch 356/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5560 - accuracy: 0.7088 - val_loss: 0.5701 - val_accuracy: 0.6341\n",
            "Epoch 357/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5556 - accuracy: 0.7026 - val_loss: 0.5697 - val_accuracy: 0.6341\n",
            "Epoch 358/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5551 - accuracy: 0.7128 - val_loss: 0.5692 - val_accuracy: 0.6341\n",
            "Epoch 359/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5544 - accuracy: 0.7108 - val_loss: 0.5688 - val_accuracy: 0.6341\n",
            "Epoch 360/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5539 - accuracy: 0.7149 - val_loss: 0.5683 - val_accuracy: 0.6504\n",
            "Epoch 361/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5532 - accuracy: 0.7108 - val_loss: 0.5679 - val_accuracy: 0.6504\n",
            "Epoch 362/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5529 - accuracy: 0.7149 - val_loss: 0.5674 - val_accuracy: 0.6423\n",
            "Epoch 363/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5522 - accuracy: 0.7128 - val_loss: 0.5670 - val_accuracy: 0.6423\n",
            "Epoch 364/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5516 - accuracy: 0.7189 - val_loss: 0.5665 - val_accuracy: 0.6423\n",
            "Epoch 365/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5512 - accuracy: 0.7149 - val_loss: 0.5660 - val_accuracy: 0.6341\n",
            "Epoch 366/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5504 - accuracy: 0.7189 - val_loss: 0.5656 - val_accuracy: 0.6423\n",
            "Epoch 367/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5499 - accuracy: 0.7210 - val_loss: 0.5651 - val_accuracy: 0.6504\n",
            "Epoch 368/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5497 - accuracy: 0.7210 - val_loss: 0.5647 - val_accuracy: 0.6504\n",
            "Epoch 369/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5489 - accuracy: 0.7210 - val_loss: 0.5642 - val_accuracy: 0.6504\n",
            "Epoch 370/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5485 - accuracy: 0.7189 - val_loss: 0.5638 - val_accuracy: 0.6504\n",
            "Epoch 371/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5478 - accuracy: 0.7210 - val_loss: 0.5634 - val_accuracy: 0.6504\n",
            "Epoch 372/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5476 - accuracy: 0.7210 - val_loss: 0.5629 - val_accuracy: 0.6504\n",
            "Epoch 373/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5467 - accuracy: 0.7189 - val_loss: 0.5625 - val_accuracy: 0.6504\n",
            "Epoch 374/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5463 - accuracy: 0.7210 - val_loss: 0.5621 - val_accuracy: 0.6504\n",
            "Epoch 375/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5459 - accuracy: 0.7230 - val_loss: 0.5616 - val_accuracy: 0.6504\n",
            "Epoch 376/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5450 - accuracy: 0.7230 - val_loss: 0.5612 - val_accuracy: 0.6504\n",
            "Epoch 377/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5445 - accuracy: 0.7210 - val_loss: 0.5607 - val_accuracy: 0.6504\n",
            "Epoch 378/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5440 - accuracy: 0.7210 - val_loss: 0.5603 - val_accuracy: 0.6504\n",
            "Epoch 379/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5434 - accuracy: 0.7210 - val_loss: 0.5598 - val_accuracy: 0.6504\n",
            "Epoch 380/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5428 - accuracy: 0.7210 - val_loss: 0.5594 - val_accuracy: 0.6504\n",
            "Epoch 381/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5424 - accuracy: 0.7210 - val_loss: 0.5589 - val_accuracy: 0.6504\n",
            "Epoch 382/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5417 - accuracy: 0.7189 - val_loss: 0.5585 - val_accuracy: 0.6504\n",
            "Epoch 383/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5412 - accuracy: 0.7210 - val_loss: 0.5581 - val_accuracy: 0.6504\n",
            "Epoch 384/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.5408 - accuracy: 0.7189 - val_loss: 0.5577 - val_accuracy: 0.6504\n",
            "Epoch 385/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5402 - accuracy: 0.7210 - val_loss: 0.5572 - val_accuracy: 0.6504\n",
            "Epoch 386/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5400 - accuracy: 0.7230 - val_loss: 0.5568 - val_accuracy: 0.6504\n",
            "Epoch 387/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5391 - accuracy: 0.7210 - val_loss: 0.5564 - val_accuracy: 0.6504\n",
            "Epoch 388/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5387 - accuracy: 0.7210 - val_loss: 0.5559 - val_accuracy: 0.6504\n",
            "Epoch 389/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5381 - accuracy: 0.7210 - val_loss: 0.5555 - val_accuracy: 0.6504\n",
            "Epoch 390/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5379 - accuracy: 0.7210 - val_loss: 0.5551 - val_accuracy: 0.6585\n",
            "Epoch 391/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5370 - accuracy: 0.7210 - val_loss: 0.5547 - val_accuracy: 0.6504\n",
            "Epoch 392/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5366 - accuracy: 0.7210 - val_loss: 0.5543 - val_accuracy: 0.6504\n",
            "Epoch 393/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5361 - accuracy: 0.7271 - val_loss: 0.5539 - val_accuracy: 0.6585\n",
            "Epoch 394/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5356 - accuracy: 0.7210 - val_loss: 0.5536 - val_accuracy: 0.6504\n",
            "Epoch 395/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5351 - accuracy: 0.7230 - val_loss: 0.5531 - val_accuracy: 0.6585\n",
            "Epoch 396/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5347 - accuracy: 0.7169 - val_loss: 0.5526 - val_accuracy: 0.6667\n",
            "Epoch 397/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5342 - accuracy: 0.7251 - val_loss: 0.5522 - val_accuracy: 0.6585\n",
            "Epoch 398/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5336 - accuracy: 0.7169 - val_loss: 0.5518 - val_accuracy: 0.6667\n",
            "Epoch 399/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5332 - accuracy: 0.7189 - val_loss: 0.5515 - val_accuracy: 0.6667\n",
            "Epoch 400/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5324 - accuracy: 0.7189 - val_loss: 0.5511 - val_accuracy: 0.6667\n",
            "Epoch 401/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5318 - accuracy: 0.7230 - val_loss: 0.5507 - val_accuracy: 0.6667\n",
            "Epoch 402/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5316 - accuracy: 0.7251 - val_loss: 0.5504 - val_accuracy: 0.6667\n",
            "Epoch 403/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5310 - accuracy: 0.7271 - val_loss: 0.5499 - val_accuracy: 0.6667\n",
            "Epoch 404/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5307 - accuracy: 0.7251 - val_loss: 0.5495 - val_accuracy: 0.6667\n",
            "Epoch 405/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5303 - accuracy: 0.7230 - val_loss: 0.5492 - val_accuracy: 0.6667\n",
            "Epoch 406/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5295 - accuracy: 0.7210 - val_loss: 0.5488 - val_accuracy: 0.6748\n",
            "Epoch 407/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5291 - accuracy: 0.7230 - val_loss: 0.5484 - val_accuracy: 0.6748\n",
            "Epoch 408/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5286 - accuracy: 0.7230 - val_loss: 0.5480 - val_accuracy: 0.6829\n",
            "Epoch 409/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5282 - accuracy: 0.7210 - val_loss: 0.5477 - val_accuracy: 0.6667\n",
            "Epoch 410/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5274 - accuracy: 0.7210 - val_loss: 0.5473 - val_accuracy: 0.6829\n",
            "Epoch 411/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5271 - accuracy: 0.7189 - val_loss: 0.5469 - val_accuracy: 0.6911\n",
            "Epoch 412/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5264 - accuracy: 0.7230 - val_loss: 0.5466 - val_accuracy: 0.6748\n",
            "Epoch 413/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5261 - accuracy: 0.7271 - val_loss: 0.5462 - val_accuracy: 0.6748\n",
            "Epoch 414/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5259 - accuracy: 0.7230 - val_loss: 0.5459 - val_accuracy: 0.6748\n",
            "Epoch 415/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5249 - accuracy: 0.7251 - val_loss: 0.5455 - val_accuracy: 0.6748\n",
            "Epoch 416/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5247 - accuracy: 0.7251 - val_loss: 0.5452 - val_accuracy: 0.6829\n",
            "Epoch 417/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5244 - accuracy: 0.7271 - val_loss: 0.5448 - val_accuracy: 0.6829\n",
            "Epoch 418/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5237 - accuracy: 0.7251 - val_loss: 0.5444 - val_accuracy: 0.6829\n",
            "Epoch 419/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.5231 - accuracy: 0.7271 - val_loss: 0.5441 - val_accuracy: 0.6829\n",
            "Epoch 420/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5229 - accuracy: 0.7271 - val_loss: 0.5438 - val_accuracy: 0.6911\n",
            "Epoch 421/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5224 - accuracy: 0.7251 - val_loss: 0.5434 - val_accuracy: 0.6992\n",
            "Epoch 422/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5220 - accuracy: 0.7271 - val_loss: 0.5431 - val_accuracy: 0.7073\n",
            "Epoch 423/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5214 - accuracy: 0.7291 - val_loss: 0.5427 - val_accuracy: 0.7073\n",
            "Epoch 424/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5210 - accuracy: 0.7332 - val_loss: 0.5423 - val_accuracy: 0.7073\n",
            "Epoch 425/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5205 - accuracy: 0.7291 - val_loss: 0.5420 - val_accuracy: 0.7073\n",
            "Epoch 426/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5199 - accuracy: 0.7332 - val_loss: 0.5417 - val_accuracy: 0.7073\n",
            "Epoch 427/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5195 - accuracy: 0.7373 - val_loss: 0.5414 - val_accuracy: 0.6911\n",
            "Epoch 428/1000\n",
            "491/491 [==============================] - 0s 53us/step - loss: 0.5192 - accuracy: 0.7291 - val_loss: 0.5411 - val_accuracy: 0.6911\n",
            "Epoch 429/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5188 - accuracy: 0.7352 - val_loss: 0.5407 - val_accuracy: 0.6911\n",
            "Epoch 430/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5186 - accuracy: 0.7393 - val_loss: 0.5404 - val_accuracy: 0.6992\n",
            "Epoch 431/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5179 - accuracy: 0.7352 - val_loss: 0.5401 - val_accuracy: 0.6992\n",
            "Epoch 432/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5174 - accuracy: 0.7373 - val_loss: 0.5399 - val_accuracy: 0.6911\n",
            "Epoch 433/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5168 - accuracy: 0.7373 - val_loss: 0.5395 - val_accuracy: 0.6911\n",
            "Epoch 434/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5163 - accuracy: 0.7373 - val_loss: 0.5391 - val_accuracy: 0.6992\n",
            "Epoch 435/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5160 - accuracy: 0.7332 - val_loss: 0.5387 - val_accuracy: 0.7073\n",
            "Epoch 436/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5155 - accuracy: 0.7393 - val_loss: 0.5384 - val_accuracy: 0.7073\n",
            "Epoch 437/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5151 - accuracy: 0.7413 - val_loss: 0.5381 - val_accuracy: 0.6992\n",
            "Epoch 438/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5144 - accuracy: 0.7352 - val_loss: 0.5378 - val_accuracy: 0.6992\n",
            "Epoch 439/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5143 - accuracy: 0.7393 - val_loss: 0.5375 - val_accuracy: 0.7073\n",
            "Epoch 440/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5136 - accuracy: 0.7434 - val_loss: 0.5372 - val_accuracy: 0.7073\n",
            "Epoch 441/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5135 - accuracy: 0.7434 - val_loss: 0.5369 - val_accuracy: 0.7073\n",
            "Epoch 442/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5128 - accuracy: 0.7413 - val_loss: 0.5366 - val_accuracy: 0.7073\n",
            "Epoch 443/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5126 - accuracy: 0.7393 - val_loss: 0.5363 - val_accuracy: 0.6992\n",
            "Epoch 444/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5120 - accuracy: 0.7413 - val_loss: 0.5360 - val_accuracy: 0.6992\n",
            "Epoch 445/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5119 - accuracy: 0.7413 - val_loss: 0.5359 - val_accuracy: 0.6992\n",
            "Epoch 446/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5112 - accuracy: 0.7393 - val_loss: 0.5356 - val_accuracy: 0.6992\n",
            "Epoch 447/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5107 - accuracy: 0.7434 - val_loss: 0.5353 - val_accuracy: 0.6992\n",
            "Epoch 448/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5103 - accuracy: 0.7434 - val_loss: 0.5349 - val_accuracy: 0.6911\n",
            "Epoch 449/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5104 - accuracy: 0.7434 - val_loss: 0.5346 - val_accuracy: 0.6911\n",
            "Epoch 450/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5095 - accuracy: 0.7393 - val_loss: 0.5343 - val_accuracy: 0.6911\n",
            "Epoch 451/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5090 - accuracy: 0.7454 - val_loss: 0.5341 - val_accuracy: 0.6911\n",
            "Epoch 452/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5089 - accuracy: 0.7454 - val_loss: 0.5337 - val_accuracy: 0.6992\n",
            "Epoch 453/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5082 - accuracy: 0.7434 - val_loss: 0.5335 - val_accuracy: 0.6992\n",
            "Epoch 454/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5079 - accuracy: 0.7454 - val_loss: 0.5332 - val_accuracy: 0.6911\n",
            "Epoch 455/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5075 - accuracy: 0.7475 - val_loss: 0.5329 - val_accuracy: 0.6992\n",
            "Epoch 456/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5074 - accuracy: 0.7495 - val_loss: 0.5326 - val_accuracy: 0.6992\n",
            "Epoch 457/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5066 - accuracy: 0.7434 - val_loss: 0.5323 - val_accuracy: 0.6992\n",
            "Epoch 458/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5063 - accuracy: 0.7434 - val_loss: 0.5321 - val_accuracy: 0.6911\n",
            "Epoch 459/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5059 - accuracy: 0.7495 - val_loss: 0.5319 - val_accuracy: 0.6911\n",
            "Epoch 460/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.5057 - accuracy: 0.7434 - val_loss: 0.5316 - val_accuracy: 0.6911\n",
            "Epoch 461/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5052 - accuracy: 0.7495 - val_loss: 0.5314 - val_accuracy: 0.6911\n",
            "Epoch 462/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5046 - accuracy: 0.7495 - val_loss: 0.5312 - val_accuracy: 0.6911\n",
            "Epoch 463/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5046 - accuracy: 0.7434 - val_loss: 0.5310 - val_accuracy: 0.6911\n",
            "Epoch 464/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5040 - accuracy: 0.7434 - val_loss: 0.5307 - val_accuracy: 0.6911\n",
            "Epoch 465/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.5036 - accuracy: 0.7475 - val_loss: 0.5305 - val_accuracy: 0.6911\n",
            "Epoch 466/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5032 - accuracy: 0.7475 - val_loss: 0.5302 - val_accuracy: 0.6911\n",
            "Epoch 467/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5027 - accuracy: 0.7495 - val_loss: 0.5299 - val_accuracy: 0.6992\n",
            "Epoch 468/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5026 - accuracy: 0.7495 - val_loss: 0.5297 - val_accuracy: 0.7073\n",
            "Epoch 469/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5021 - accuracy: 0.7495 - val_loss: 0.5294 - val_accuracy: 0.6911\n",
            "Epoch 470/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5017 - accuracy: 0.7495 - val_loss: 0.5292 - val_accuracy: 0.7073\n",
            "Epoch 471/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5015 - accuracy: 0.7495 - val_loss: 0.5290 - val_accuracy: 0.7073\n",
            "Epoch 472/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5012 - accuracy: 0.7475 - val_loss: 0.5288 - val_accuracy: 0.7073\n",
            "Epoch 473/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5009 - accuracy: 0.7475 - val_loss: 0.5285 - val_accuracy: 0.7073\n",
            "Epoch 474/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5003 - accuracy: 0.7515 - val_loss: 0.5283 - val_accuracy: 0.7073\n",
            "Epoch 475/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5001 - accuracy: 0.7495 - val_loss: 0.5281 - val_accuracy: 0.6992\n",
            "Epoch 476/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4995 - accuracy: 0.7475 - val_loss: 0.5280 - val_accuracy: 0.6911\n",
            "Epoch 477/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4990 - accuracy: 0.7515 - val_loss: 0.5277 - val_accuracy: 0.6911\n",
            "Epoch 478/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4991 - accuracy: 0.7576 - val_loss: 0.5274 - val_accuracy: 0.6992\n",
            "Epoch 479/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4983 - accuracy: 0.7495 - val_loss: 0.5272 - val_accuracy: 0.6992\n",
            "Epoch 480/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4983 - accuracy: 0.7515 - val_loss: 0.5270 - val_accuracy: 0.6992\n",
            "Epoch 481/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4981 - accuracy: 0.7536 - val_loss: 0.5268 - val_accuracy: 0.6992\n",
            "Epoch 482/1000\n",
            "491/491 [==============================] - 0s 51us/step - loss: 0.4979 - accuracy: 0.7556 - val_loss: 0.5266 - val_accuracy: 0.6992\n",
            "Epoch 483/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4968 - accuracy: 0.7495 - val_loss: 0.5264 - val_accuracy: 0.6992\n",
            "Epoch 484/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4969 - accuracy: 0.7556 - val_loss: 0.5261 - val_accuracy: 0.6992\n",
            "Epoch 485/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4965 - accuracy: 0.7536 - val_loss: 0.5259 - val_accuracy: 0.6992\n",
            "Epoch 486/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4962 - accuracy: 0.7536 - val_loss: 0.5257 - val_accuracy: 0.6992\n",
            "Epoch 487/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4957 - accuracy: 0.7536 - val_loss: 0.5255 - val_accuracy: 0.7073\n",
            "Epoch 488/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4955 - accuracy: 0.7556 - val_loss: 0.5253 - val_accuracy: 0.6992\n",
            "Epoch 489/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4949 - accuracy: 0.7515 - val_loss: 0.5251 - val_accuracy: 0.6992\n",
            "Epoch 490/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4950 - accuracy: 0.7576 - val_loss: 0.5249 - val_accuracy: 0.6992\n",
            "Epoch 491/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4942 - accuracy: 0.7515 - val_loss: 0.5247 - val_accuracy: 0.6992\n",
            "Epoch 492/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4940 - accuracy: 0.7536 - val_loss: 0.5245 - val_accuracy: 0.6992\n",
            "Epoch 493/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4940 - accuracy: 0.7556 - val_loss: 0.5244 - val_accuracy: 0.6992\n",
            "Epoch 494/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4937 - accuracy: 0.7556 - val_loss: 0.5242 - val_accuracy: 0.7073\n",
            "Epoch 495/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4937 - accuracy: 0.7597 - val_loss: 0.5240 - val_accuracy: 0.6992\n",
            "Epoch 496/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4926 - accuracy: 0.7576 - val_loss: 0.5238 - val_accuracy: 0.6992\n",
            "Epoch 497/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4926 - accuracy: 0.7597 - val_loss: 0.5236 - val_accuracy: 0.6992\n",
            "Epoch 498/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4918 - accuracy: 0.7576 - val_loss: 0.5234 - val_accuracy: 0.6992\n",
            "Epoch 499/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4921 - accuracy: 0.7597 - val_loss: 0.5232 - val_accuracy: 0.6992\n",
            "Epoch 500/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4917 - accuracy: 0.7597 - val_loss: 0.5232 - val_accuracy: 0.6992\n",
            "Epoch 501/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4912 - accuracy: 0.7597 - val_loss: 0.5232 - val_accuracy: 0.6992\n",
            "Epoch 502/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4909 - accuracy: 0.7576 - val_loss: 0.5228 - val_accuracy: 0.6992\n",
            "Epoch 503/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4907 - accuracy: 0.7576 - val_loss: 0.5226 - val_accuracy: 0.6992\n",
            "Epoch 504/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4904 - accuracy: 0.7576 - val_loss: 0.5225 - val_accuracy: 0.6992\n",
            "Epoch 505/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4902 - accuracy: 0.7597 - val_loss: 0.5222 - val_accuracy: 0.6992\n",
            "Epoch 506/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4897 - accuracy: 0.7617 - val_loss: 0.5222 - val_accuracy: 0.6992\n",
            "Epoch 507/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4896 - accuracy: 0.7576 - val_loss: 0.5219 - val_accuracy: 0.6992\n",
            "Epoch 508/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4894 - accuracy: 0.7617 - val_loss: 0.5218 - val_accuracy: 0.6992\n",
            "Epoch 509/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4889 - accuracy: 0.7637 - val_loss: 0.5216 - val_accuracy: 0.6992\n",
            "Epoch 510/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4885 - accuracy: 0.7658 - val_loss: 0.5215 - val_accuracy: 0.6992\n",
            "Epoch 511/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4882 - accuracy: 0.7576 - val_loss: 0.5214 - val_accuracy: 0.6992\n",
            "Epoch 512/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4879 - accuracy: 0.7597 - val_loss: 0.5212 - val_accuracy: 0.6992\n",
            "Epoch 513/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4876 - accuracy: 0.7597 - val_loss: 0.5210 - val_accuracy: 0.6992\n",
            "Epoch 514/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4871 - accuracy: 0.7658 - val_loss: 0.5209 - val_accuracy: 0.6992\n",
            "Epoch 515/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4869 - accuracy: 0.7637 - val_loss: 0.5207 - val_accuracy: 0.6992\n",
            "Epoch 516/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4867 - accuracy: 0.7617 - val_loss: 0.5206 - val_accuracy: 0.6992\n",
            "Epoch 517/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4861 - accuracy: 0.7637 - val_loss: 0.5204 - val_accuracy: 0.6992\n",
            "Epoch 518/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4858 - accuracy: 0.7637 - val_loss: 0.5202 - val_accuracy: 0.6992\n",
            "Epoch 519/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4858 - accuracy: 0.7617 - val_loss: 0.5201 - val_accuracy: 0.7073\n",
            "Epoch 520/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4854 - accuracy: 0.7658 - val_loss: 0.5199 - val_accuracy: 0.7073\n",
            "Epoch 521/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4853 - accuracy: 0.7617 - val_loss: 0.5198 - val_accuracy: 0.7154\n",
            "Epoch 522/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4847 - accuracy: 0.7658 - val_loss: 0.5197 - val_accuracy: 0.7073\n",
            "Epoch 523/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4845 - accuracy: 0.7658 - val_loss: 0.5197 - val_accuracy: 0.6992\n",
            "Epoch 524/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4841 - accuracy: 0.7699 - val_loss: 0.5194 - val_accuracy: 0.7154\n",
            "Epoch 525/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4842 - accuracy: 0.7699 - val_loss: 0.5192 - val_accuracy: 0.7154\n",
            "Epoch 526/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4842 - accuracy: 0.7658 - val_loss: 0.5191 - val_accuracy: 0.7154\n",
            "Epoch 527/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4833 - accuracy: 0.7719 - val_loss: 0.5189 - val_accuracy: 0.7154\n",
            "Epoch 528/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4838 - accuracy: 0.7658 - val_loss: 0.5188 - val_accuracy: 0.7154\n",
            "Epoch 529/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4830 - accuracy: 0.7658 - val_loss: 0.5186 - val_accuracy: 0.7154\n",
            "Epoch 530/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4823 - accuracy: 0.7678 - val_loss: 0.5185 - val_accuracy: 0.7154\n",
            "Epoch 531/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4825 - accuracy: 0.7658 - val_loss: 0.5184 - val_accuracy: 0.7154\n",
            "Epoch 532/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4819 - accuracy: 0.7699 - val_loss: 0.5182 - val_accuracy: 0.7154\n",
            "Epoch 533/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4817 - accuracy: 0.7678 - val_loss: 0.5181 - val_accuracy: 0.7154\n",
            "Epoch 534/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4817 - accuracy: 0.7678 - val_loss: 0.5180 - val_accuracy: 0.7154\n",
            "Epoch 535/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4811 - accuracy: 0.7699 - val_loss: 0.5179 - val_accuracy: 0.7154\n",
            "Epoch 536/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4809 - accuracy: 0.7719 - val_loss: 0.5178 - val_accuracy: 0.7154\n",
            "Epoch 537/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4806 - accuracy: 0.7699 - val_loss: 0.5177 - val_accuracy: 0.7154\n",
            "Epoch 538/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4805 - accuracy: 0.7678 - val_loss: 0.5175 - val_accuracy: 0.7154\n",
            "Epoch 539/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4800 - accuracy: 0.7699 - val_loss: 0.5175 - val_accuracy: 0.7154\n",
            "Epoch 540/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4798 - accuracy: 0.7678 - val_loss: 0.5174 - val_accuracy: 0.7154\n",
            "Epoch 541/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4797 - accuracy: 0.7678 - val_loss: 0.5175 - val_accuracy: 0.6992\n",
            "Epoch 542/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4798 - accuracy: 0.7739 - val_loss: 0.5172 - val_accuracy: 0.7073\n",
            "Epoch 543/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4790 - accuracy: 0.7719 - val_loss: 0.5170 - val_accuracy: 0.7154\n",
            "Epoch 544/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4798 - accuracy: 0.7699 - val_loss: 0.5168 - val_accuracy: 0.7154\n",
            "Epoch 545/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4787 - accuracy: 0.7719 - val_loss: 0.5167 - val_accuracy: 0.7154\n",
            "Epoch 546/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4781 - accuracy: 0.7739 - val_loss: 0.5165 - val_accuracy: 0.7154\n",
            "Epoch 547/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4785 - accuracy: 0.7699 - val_loss: 0.5164 - val_accuracy: 0.7073\n",
            "Epoch 548/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4779 - accuracy: 0.7719 - val_loss: 0.5162 - val_accuracy: 0.7154\n",
            "Epoch 549/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4780 - accuracy: 0.7719 - val_loss: 0.5161 - val_accuracy: 0.7154\n",
            "Epoch 550/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4775 - accuracy: 0.7760 - val_loss: 0.5159 - val_accuracy: 0.7154\n",
            "Epoch 551/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4774 - accuracy: 0.7719 - val_loss: 0.5160 - val_accuracy: 0.7073\n",
            "Epoch 552/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4771 - accuracy: 0.7780 - val_loss: 0.5158 - val_accuracy: 0.7073\n",
            "Epoch 553/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4765 - accuracy: 0.7760 - val_loss: 0.5156 - val_accuracy: 0.7073\n",
            "Epoch 554/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4765 - accuracy: 0.7739 - val_loss: 0.5155 - val_accuracy: 0.7154\n",
            "Epoch 555/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4768 - accuracy: 0.7760 - val_loss: 0.5154 - val_accuracy: 0.7154\n",
            "Epoch 556/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4761 - accuracy: 0.7699 - val_loss: 0.5153 - val_accuracy: 0.7154\n",
            "Epoch 557/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4759 - accuracy: 0.7739 - val_loss: 0.5152 - val_accuracy: 0.7073\n",
            "Epoch 558/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4753 - accuracy: 0.7739 - val_loss: 0.5152 - val_accuracy: 0.7073\n",
            "Epoch 559/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7154\n",
            "Epoch 560/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4750 - accuracy: 0.7780 - val_loss: 0.5149 - val_accuracy: 0.7154\n",
            "Epoch 561/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4748 - accuracy: 0.7739 - val_loss: 0.5148 - val_accuracy: 0.7236\n",
            "Epoch 562/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4744 - accuracy: 0.7760 - val_loss: 0.5147 - val_accuracy: 0.7073\n",
            "Epoch 563/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4745 - accuracy: 0.7760 - val_loss: 0.5146 - val_accuracy: 0.7154\n",
            "Epoch 564/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4742 - accuracy: 0.7699 - val_loss: 0.5147 - val_accuracy: 0.7236\n",
            "Epoch 565/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4745 - accuracy: 0.7760 - val_loss: 0.5144 - val_accuracy: 0.7154\n",
            "Epoch 566/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4738 - accuracy: 0.7780 - val_loss: 0.5143 - val_accuracy: 0.7154\n",
            "Epoch 567/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4736 - accuracy: 0.7719 - val_loss: 0.5143 - val_accuracy: 0.7236\n",
            "Epoch 568/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4735 - accuracy: 0.7739 - val_loss: 0.5142 - val_accuracy: 0.7154\n",
            "Epoch 569/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4732 - accuracy: 0.7719 - val_loss: 0.5141 - val_accuracy: 0.7236\n",
            "Epoch 570/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.4731 - accuracy: 0.7739 - val_loss: 0.5140 - val_accuracy: 0.7154\n",
            "Epoch 571/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4729 - accuracy: 0.7719 - val_loss: 0.5142 - val_accuracy: 0.7317\n",
            "Epoch 572/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4724 - accuracy: 0.7739 - val_loss: 0.5140 - val_accuracy: 0.7317\n",
            "Epoch 573/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4723 - accuracy: 0.7719 - val_loss: 0.5139 - val_accuracy: 0.7317\n",
            "Epoch 574/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4723 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7317\n",
            "Epoch 575/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7236\n",
            "Epoch 576/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7154\n",
            "Epoch 577/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4716 - accuracy: 0.7699 - val_loss: 0.5135 - val_accuracy: 0.7236\n",
            "Epoch 578/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4716 - accuracy: 0.7719 - val_loss: 0.5134 - val_accuracy: 0.7236\n",
            "Epoch 579/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4715 - accuracy: 0.7739 - val_loss: 0.5134 - val_accuracy: 0.7154\n",
            "Epoch 580/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4709 - accuracy: 0.7719 - val_loss: 0.5133 - val_accuracy: 0.7236\n",
            "Epoch 581/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4710 - accuracy: 0.7699 - val_loss: 0.5133 - val_accuracy: 0.7317\n",
            "Epoch 582/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4707 - accuracy: 0.7739 - val_loss: 0.5131 - val_accuracy: 0.7236\n",
            "Epoch 583/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4707 - accuracy: 0.7739 - val_loss: 0.5130 - val_accuracy: 0.7236\n",
            "Epoch 584/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4707 - accuracy: 0.7719 - val_loss: 0.5130 - val_accuracy: 0.7236\n",
            "Epoch 585/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4702 - accuracy: 0.7658 - val_loss: 0.5130 - val_accuracy: 0.7317\n",
            "Epoch 586/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4701 - accuracy: 0.7719 - val_loss: 0.5128 - val_accuracy: 0.7154\n",
            "Epoch 587/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4698 - accuracy: 0.7719 - val_loss: 0.5127 - val_accuracy: 0.7154\n",
            "Epoch 588/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4702 - accuracy: 0.7739 - val_loss: 0.5127 - val_accuracy: 0.7236\n",
            "Epoch 589/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4691 - accuracy: 0.7719 - val_loss: 0.5127 - val_accuracy: 0.7236\n",
            "Epoch 590/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4694 - accuracy: 0.7739 - val_loss: 0.5125 - val_accuracy: 0.7154\n",
            "Epoch 591/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4694 - accuracy: 0.7719 - val_loss: 0.5125 - val_accuracy: 0.7236\n",
            "Epoch 592/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4692 - accuracy: 0.7739 - val_loss: 0.5125 - val_accuracy: 0.7236\n",
            "Epoch 593/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4688 - accuracy: 0.7719 - val_loss: 0.5124 - val_accuracy: 0.7236\n",
            "Epoch 594/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4690 - accuracy: 0.7699 - val_loss: 0.5123 - val_accuracy: 0.7236\n",
            "Epoch 595/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4685 - accuracy: 0.7739 - val_loss: 0.5123 - val_accuracy: 0.7236\n",
            "Epoch 596/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4682 - accuracy: 0.7719 - val_loss: 0.5123 - val_accuracy: 0.7317\n",
            "Epoch 597/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4677 - accuracy: 0.7699 - val_loss: 0.5121 - val_accuracy: 0.7236\n",
            "Epoch 598/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7236\n",
            "Epoch 599/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4683 - accuracy: 0.7739 - val_loss: 0.5120 - val_accuracy: 0.7236\n",
            "Epoch 600/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4676 - accuracy: 0.7719 - val_loss: 0.5119 - val_accuracy: 0.7236\n",
            "Epoch 601/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.5119 - val_accuracy: 0.7317\n",
            "Epoch 602/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.5122 - val_accuracy: 0.7398\n",
            "Epoch 603/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4672 - accuracy: 0.7617 - val_loss: 0.5116 - val_accuracy: 0.7236\n",
            "Epoch 604/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4666 - accuracy: 0.7699 - val_loss: 0.5115 - val_accuracy: 0.7236\n",
            "Epoch 605/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4671 - accuracy: 0.7739 - val_loss: 0.5114 - val_accuracy: 0.7236\n",
            "Epoch 606/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4664 - accuracy: 0.7719 - val_loss: 0.5114 - val_accuracy: 0.7236\n",
            "Epoch 607/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7317\n",
            "Epoch 608/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4665 - accuracy: 0.7699 - val_loss: 0.5114 - val_accuracy: 0.7398\n",
            "Epoch 609/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4666 - accuracy: 0.7699 - val_loss: 0.5112 - val_accuracy: 0.7398\n",
            "Epoch 610/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4658 - accuracy: 0.7658 - val_loss: 0.5109 - val_accuracy: 0.7236\n",
            "Epoch 611/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4655 - accuracy: 0.7719 - val_loss: 0.5109 - val_accuracy: 0.7236\n",
            "Epoch 612/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4654 - accuracy: 0.7739 - val_loss: 0.5108 - val_accuracy: 0.7236\n",
            "Epoch 613/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4655 - accuracy: 0.7739 - val_loss: 0.5108 - val_accuracy: 0.7398\n",
            "Epoch 614/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4655 - accuracy: 0.7719 - val_loss: 0.5106 - val_accuracy: 0.7398\n",
            "Epoch 615/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4654 - accuracy: 0.7699 - val_loss: 0.5104 - val_accuracy: 0.7398\n",
            "Epoch 616/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4653 - accuracy: 0.7678 - val_loss: 0.5103 - val_accuracy: 0.7236\n",
            "Epoch 617/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4647 - accuracy: 0.7719 - val_loss: 0.5102 - val_accuracy: 0.7236\n",
            "Epoch 618/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4648 - accuracy: 0.7739 - val_loss: 0.5102 - val_accuracy: 0.7398\n",
            "Epoch 619/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4652 - accuracy: 0.7699 - val_loss: 0.5102 - val_accuracy: 0.7398\n",
            "Epoch 620/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4643 - accuracy: 0.7699 - val_loss: 0.5100 - val_accuracy: 0.7398\n",
            "Epoch 621/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4642 - accuracy: 0.7719 - val_loss: 0.5101 - val_accuracy: 0.7398\n",
            "Epoch 622/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4644 - accuracy: 0.7678 - val_loss: 0.5099 - val_accuracy: 0.7398\n",
            "Epoch 623/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4637 - accuracy: 0.7699 - val_loss: 0.5097 - val_accuracy: 0.7317\n",
            "Epoch 624/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4635 - accuracy: 0.7739 - val_loss: 0.5097 - val_accuracy: 0.7317\n",
            "Epoch 625/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4642 - accuracy: 0.7739 - val_loss: 0.5098 - val_accuracy: 0.7317\n",
            "Epoch 626/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.5095 - val_accuracy: 0.7317\n",
            "Epoch 627/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4636 - accuracy: 0.7699 - val_loss: 0.5094 - val_accuracy: 0.7236\n",
            "Epoch 628/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4632 - accuracy: 0.7678 - val_loss: 0.5093 - val_accuracy: 0.7317\n",
            "Epoch 629/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4629 - accuracy: 0.7719 - val_loss: 0.5093 - val_accuracy: 0.7317\n",
            "Epoch 630/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4629 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7398\n",
            "Epoch 631/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4626 - accuracy: 0.7678 - val_loss: 0.5091 - val_accuracy: 0.7398\n",
            "Epoch 632/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.5091 - val_accuracy: 0.7480\n",
            "Epoch 633/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4624 - accuracy: 0.7719 - val_loss: 0.5091 - val_accuracy: 0.7317\n",
            "Epoch 634/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4625 - accuracy: 0.7719 - val_loss: 0.5089 - val_accuracy: 0.7398\n",
            "Epoch 635/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4627 - accuracy: 0.7719 - val_loss: 0.5088 - val_accuracy: 0.7398\n",
            "Epoch 636/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4622 - accuracy: 0.7739 - val_loss: 0.5088 - val_accuracy: 0.7398\n",
            "Epoch 637/1000\n",
            "491/491 [==============================] - 0s 51us/step - loss: 0.4619 - accuracy: 0.7719 - val_loss: 0.5086 - val_accuracy: 0.7398\n",
            "Epoch 638/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4618 - accuracy: 0.7780 - val_loss: 0.5087 - val_accuracy: 0.7236\n",
            "Epoch 639/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4617 - accuracy: 0.7739 - val_loss: 0.5084 - val_accuracy: 0.7317\n",
            "Epoch 640/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5084 - val_accuracy: 0.7317\n",
            "Epoch 641/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4615 - accuracy: 0.7719 - val_loss: 0.5083 - val_accuracy: 0.7317\n",
            "Epoch 642/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5082 - val_accuracy: 0.7317\n",
            "Epoch 643/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4611 - accuracy: 0.7739 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 644/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4613 - accuracy: 0.7739 - val_loss: 0.5081 - val_accuracy: 0.7317\n",
            "Epoch 645/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4614 - accuracy: 0.7719 - val_loss: 0.5080 - val_accuracy: 0.7317\n",
            "Epoch 646/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4614 - accuracy: 0.7739 - val_loss: 0.5079 - val_accuracy: 0.7317\n",
            "Epoch 647/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7317\n",
            "Epoch 648/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.5080 - val_accuracy: 0.7398\n",
            "Epoch 649/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7398\n",
            "Epoch 650/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 651/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7317\n",
            "Epoch 652/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7317\n",
            "Epoch 653/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.5076 - val_accuracy: 0.7236\n",
            "Epoch 654/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4602 - accuracy: 0.7739 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 655/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7398\n",
            "Epoch 656/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4601 - accuracy: 0.7739 - val_loss: 0.5076 - val_accuracy: 0.7398\n",
            "Epoch 657/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4603 - accuracy: 0.7739 - val_loss: 0.5073 - val_accuracy: 0.7317\n",
            "Epoch 658/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7236\n",
            "Epoch 659/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7236\n",
            "Epoch 660/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4593 - accuracy: 0.7719 - val_loss: 0.5073 - val_accuracy: 0.7317\n",
            "Epoch 661/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4592 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7317\n",
            "Epoch 662/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4587 - accuracy: 0.7780 - val_loss: 0.5070 - val_accuracy: 0.7317\n",
            "Epoch 663/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4593 - accuracy: 0.7780 - val_loss: 0.5070 - val_accuracy: 0.7317\n",
            "Epoch 664/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4586 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7317\n",
            "Epoch 665/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7236\n",
            "Epoch 666/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7317\n",
            "Epoch 667/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4584 - accuracy: 0.7780 - val_loss: 0.5068 - val_accuracy: 0.7317\n",
            "Epoch 668/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.5068 - val_accuracy: 0.7317\n",
            "Epoch 669/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4580 - accuracy: 0.7780 - val_loss: 0.5070 - val_accuracy: 0.7398\n",
            "Epoch 670/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.5068 - val_accuracy: 0.7317\n",
            "Epoch 671/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.5068 - val_accuracy: 0.7398\n",
            "Epoch 672/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4577 - accuracy: 0.7780 - val_loss: 0.5070 - val_accuracy: 0.7398\n",
            "Epoch 673/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.5066 - val_accuracy: 0.7317\n",
            "Epoch 674/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4576 - accuracy: 0.7719 - val_loss: 0.5067 - val_accuracy: 0.7398\n",
            "Epoch 675/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.5065 - val_accuracy: 0.7317\n",
            "Epoch 676/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4569 - accuracy: 0.7780 - val_loss: 0.5065 - val_accuracy: 0.7317\n",
            "Epoch 677/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4574 - accuracy: 0.7699 - val_loss: 0.5065 - val_accuracy: 0.7398\n",
            "Epoch 678/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.5064 - val_accuracy: 0.7317\n",
            "Epoch 679/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.5064 - val_accuracy: 0.7317\n",
            "Epoch 680/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4573 - accuracy: 0.7800 - val_loss: 0.5062 - val_accuracy: 0.7317\n",
            "Epoch 681/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4575 - accuracy: 0.7780 - val_loss: 0.5062 - val_accuracy: 0.7317\n",
            "Epoch 682/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.5063 - val_accuracy: 0.7398\n",
            "Epoch 683/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4567 - accuracy: 0.7739 - val_loss: 0.5060 - val_accuracy: 0.7317\n",
            "Epoch 684/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4565 - accuracy: 0.7739 - val_loss: 0.5061 - val_accuracy: 0.7317\n",
            "Epoch 685/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4569 - accuracy: 0.7760 - val_loss: 0.5062 - val_accuracy: 0.7398\n",
            "Epoch 686/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4569 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7317\n",
            "Epoch 687/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4558 - accuracy: 0.7739 - val_loss: 0.5058 - val_accuracy: 0.7317\n",
            "Epoch 688/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4558 - accuracy: 0.7739 - val_loss: 0.5058 - val_accuracy: 0.7317\n",
            "Epoch 689/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7317\n",
            "Epoch 690/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4557 - accuracy: 0.7739 - val_loss: 0.5058 - val_accuracy: 0.7398\n",
            "Epoch 691/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4555 - accuracy: 0.7739 - val_loss: 0.5056 - val_accuracy: 0.7317\n",
            "Epoch 692/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4561 - accuracy: 0.7780 - val_loss: 0.5056 - val_accuracy: 0.7317\n",
            "Epoch 693/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4559 - accuracy: 0.7780 - val_loss: 0.5055 - val_accuracy: 0.7317\n",
            "Epoch 694/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4552 - accuracy: 0.7739 - val_loss: 0.5056 - val_accuracy: 0.7317\n",
            "Epoch 695/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7317\n",
            "Epoch 696/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4552 - accuracy: 0.7800 - val_loss: 0.5054 - val_accuracy: 0.7317\n",
            "Epoch 697/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4551 - accuracy: 0.7719 - val_loss: 0.5053 - val_accuracy: 0.7317\n",
            "Epoch 698/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4551 - accuracy: 0.7739 - val_loss: 0.5053 - val_accuracy: 0.7317\n",
            "Epoch 699/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7317\n",
            "Epoch 700/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 701/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4549 - accuracy: 0.7739 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 702/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 703/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4551 - accuracy: 0.7800 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 704/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4544 - accuracy: 0.7780 - val_loss: 0.5053 - val_accuracy: 0.7317\n",
            "Epoch 705/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4544 - accuracy: 0.7800 - val_loss: 0.5052 - val_accuracy: 0.7398\n",
            "Epoch 706/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4546 - accuracy: 0.7780 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 707/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4546 - accuracy: 0.7780 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 708/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4547 - accuracy: 0.7800 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 709/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4543 - accuracy: 0.7739 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 710/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4537 - accuracy: 0.7760 - val_loss: 0.5050 - val_accuracy: 0.7317\n",
            "Epoch 711/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4538 - accuracy: 0.7760 - val_loss: 0.5050 - val_accuracy: 0.7398\n",
            "Epoch 712/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4539 - accuracy: 0.7739 - val_loss: 0.5051 - val_accuracy: 0.7317\n",
            "Epoch 713/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4535 - accuracy: 0.7739 - val_loss: 0.5050 - val_accuracy: 0.7317\n",
            "Epoch 714/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4541 - accuracy: 0.7780 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
            "Epoch 715/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4539 - accuracy: 0.7800 - val_loss: 0.5048 - val_accuracy: 0.7398\n",
            "Epoch 716/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5048 - val_accuracy: 0.7317\n",
            "Epoch 717/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4533 - accuracy: 0.7780 - val_loss: 0.5047 - val_accuracy: 0.7398\n",
            "Epoch 718/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4530 - accuracy: 0.7739 - val_loss: 0.5046 - val_accuracy: 0.7398\n",
            "Epoch 719/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 720/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4533 - accuracy: 0.7800 - val_loss: 0.5045 - val_accuracy: 0.7398\n",
            "Epoch 721/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5045 - val_accuracy: 0.7398\n",
            "Epoch 722/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7398\n",
            "Epoch 723/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4531 - accuracy: 0.7821 - val_loss: 0.5044 - val_accuracy: 0.7398\n",
            "Epoch 724/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4525 - accuracy: 0.7821 - val_loss: 0.5044 - val_accuracy: 0.7398\n",
            "Epoch 725/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4531 - accuracy: 0.7821 - val_loss: 0.5043 - val_accuracy: 0.7398\n",
            "Epoch 726/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4526 - accuracy: 0.7800 - val_loss: 0.5043 - val_accuracy: 0.7398\n",
            "Epoch 727/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.5043 - val_accuracy: 0.7398\n",
            "Epoch 728/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4527 - accuracy: 0.7780 - val_loss: 0.5043 - val_accuracy: 0.7398\n",
            "Epoch 729/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4520 - accuracy: 0.7760 - val_loss: 0.5042 - val_accuracy: 0.7398\n",
            "Epoch 730/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4528 - accuracy: 0.7780 - val_loss: 0.5041 - val_accuracy: 0.7398\n",
            "Epoch 731/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4517 - accuracy: 0.7821 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 732/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4529 - accuracy: 0.7780 - val_loss: 0.5042 - val_accuracy: 0.7398\n",
            "Epoch 733/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4523 - accuracy: 0.7800 - val_loss: 0.5047 - val_accuracy: 0.7561\n",
            "Epoch 734/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4527 - accuracy: 0.7780 - val_loss: 0.5044 - val_accuracy: 0.7561\n",
            "Epoch 735/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4513 - accuracy: 0.7821 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 736/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4514 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 737/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4514 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 738/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4522 - accuracy: 0.7841 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 739/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4512 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 740/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4517 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 741/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4512 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 742/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 743/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4509 - accuracy: 0.7821 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 744/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4508 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 745/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4511 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 746/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4505 - accuracy: 0.7739 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 747/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4511 - accuracy: 0.7862 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 748/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4503 - accuracy: 0.7841 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 749/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4506 - accuracy: 0.7800 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
            "Epoch 750/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4507 - accuracy: 0.7821 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 751/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4502 - accuracy: 0.7821 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 752/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4508 - accuracy: 0.7862 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 753/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.4503 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 754/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 755/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4508 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7561\n",
            "Epoch 756/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4500 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 757/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 758/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4497 - accuracy: 0.7841 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 759/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4494 - accuracy: 0.7821 - val_loss: 0.5043 - val_accuracy: 0.7561\n",
            "Epoch 760/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4506 - accuracy: 0.7862 - val_loss: 0.5042 - val_accuracy: 0.7561\n",
            "Epoch 761/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4498 - accuracy: 0.7800 - val_loss: 0.5042 - val_accuracy: 0.7561\n",
            "Epoch 762/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4495 - accuracy: 0.7841 - val_loss: 0.5042 - val_accuracy: 0.7642\n",
            "Epoch 763/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4494 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7561\n",
            "Epoch 764/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4493 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 765/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4500 - accuracy: 0.7841 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 766/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4495 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 767/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4494 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 768/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4493 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 769/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4489 - accuracy: 0.7841 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 770/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4490 - accuracy: 0.7800 - val_loss: 0.5042 - val_accuracy: 0.7561\n",
            "Epoch 771/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4489 - accuracy: 0.7841 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
            "Epoch 772/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4489 - accuracy: 0.7800 - val_loss: 0.5040 - val_accuracy: 0.7561\n",
            "Epoch 773/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4485 - accuracy: 0.7862 - val_loss: 0.5040 - val_accuracy: 0.7561\n",
            "Epoch 774/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4485 - accuracy: 0.7862 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 775/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
            "Epoch 776/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 777/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4482 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 778/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4483 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 779/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4484 - accuracy: 0.7841 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 780/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4484 - accuracy: 0.7800 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
            "Epoch 781/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4481 - accuracy: 0.7841 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
            "Epoch 782/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 783/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4480 - accuracy: 0.7862 - val_loss: 0.5038 - val_accuracy: 0.7561\n",
            "Epoch 784/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4482 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 785/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 786/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 787/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4480 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7561\n",
            "Epoch 788/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4476 - accuracy: 0.7821 - val_loss: 0.5038 - val_accuracy: 0.7561\n",
            "Epoch 789/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4473 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7561\n",
            "Epoch 790/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4475 - accuracy: 0.7862 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 791/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4482 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7561\n",
            "Epoch 792/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4474 - accuracy: 0.7862 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 793/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4472 - accuracy: 0.7862 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 794/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4473 - accuracy: 0.7923 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 795/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4470 - accuracy: 0.7841 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 796/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4471 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 797/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 798/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4468 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7642\n",
            "Epoch 799/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4466 - accuracy: 0.7862 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 800/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4467 - accuracy: 0.7841 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 801/1000\n",
            "491/491 [==============================] - 0s 30us/step - loss: 0.4474 - accuracy: 0.7739 - val_loss: 0.5037 - val_accuracy: 0.7480\n",
            "Epoch 802/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4466 - accuracy: 0.7862 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 803/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4470 - accuracy: 0.7841 - val_loss: 0.5037 - val_accuracy: 0.7480\n",
            "Epoch 804/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4470 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 805/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 806/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4462 - accuracy: 0.7902 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 807/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4461 - accuracy: 0.7800 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 808/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4463 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 809/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 810/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4463 - accuracy: 0.7821 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 811/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4465 - accuracy: 0.7821 - val_loss: 0.5034 - val_accuracy: 0.7561\n",
            "Epoch 812/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4456 - accuracy: 0.7841 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 813/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4462 - accuracy: 0.7841 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 814/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4466 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7480\n",
            "Epoch 815/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4460 - accuracy: 0.7862 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
            "Epoch 816/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4468 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7480\n",
            "Epoch 817/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4458 - accuracy: 0.7841 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 818/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4454 - accuracy: 0.7821 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
            "Epoch 819/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4455 - accuracy: 0.7841 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 820/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 821/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4458 - accuracy: 0.7862 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
            "Epoch 822/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4456 - accuracy: 0.7841 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 823/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4461 - accuracy: 0.7821 - val_loss: 0.5032 - val_accuracy: 0.7480\n",
            "Epoch 824/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4456 - accuracy: 0.7841 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
            "Epoch 825/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4455 - accuracy: 0.7821 - val_loss: 0.5033 - val_accuracy: 0.7561\n",
            "Epoch 826/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4450 - accuracy: 0.7862 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 827/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4448 - accuracy: 0.7821 - val_loss: 0.5034 - val_accuracy: 0.7561\n",
            "Epoch 828/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4449 - accuracy: 0.7800 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
            "Epoch 829/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4445 - accuracy: 0.7821 - val_loss: 0.5034 - val_accuracy: 0.7561\n",
            "Epoch 830/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4449 - accuracy: 0.7841 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 831/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4449 - accuracy: 0.7841 - val_loss: 0.5034 - val_accuracy: 0.7480\n",
            "Epoch 832/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4449 - accuracy: 0.7841 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 833/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4443 - accuracy: 0.7862 - val_loss: 0.5034 - val_accuracy: 0.7480\n",
            "Epoch 834/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
            "Epoch 835/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4442 - accuracy: 0.7841 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 836/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4449 - accuracy: 0.7821 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 837/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4444 - accuracy: 0.7862 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 838/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4448 - accuracy: 0.7862 - val_loss: 0.5035 - val_accuracy: 0.7480\n",
            "Epoch 839/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4451 - accuracy: 0.7821 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 840/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4451 - accuracy: 0.7902 - val_loss: 0.5036 - val_accuracy: 0.7561\n",
            "Epoch 841/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4442 - accuracy: 0.7841 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
            "Epoch 842/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4450 - accuracy: 0.7841 - val_loss: 0.5036 - val_accuracy: 0.7480\n",
            "Epoch 843/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.7841 - val_loss: 0.5036 - val_accuracy: 0.7480\n",
            "Epoch 844/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4440 - accuracy: 0.7862 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 845/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4439 - accuracy: 0.7862 - val_loss: 0.5037 - val_accuracy: 0.7561\n",
            "Epoch 846/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4440 - accuracy: 0.7862 - val_loss: 0.5040 - val_accuracy: 0.7561\n",
            "Epoch 847/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4450 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7480\n",
            "Epoch 848/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4440 - accuracy: 0.7862 - val_loss: 0.5037 - val_accuracy: 0.7480\n",
            "Epoch 849/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7480\n",
            "Epoch 850/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4438 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7480\n",
            "Epoch 851/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4434 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 852/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4441 - accuracy: 0.7841 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 853/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 854/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4438 - accuracy: 0.7902 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 855/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4431 - accuracy: 0.7821 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 856/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4436 - accuracy: 0.7821 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 857/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4439 - accuracy: 0.7862 - val_loss: 0.5041 - val_accuracy: 0.7561\n",
            "Epoch 858/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4436 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 859/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4431 - accuracy: 0.7841 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 860/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4438 - accuracy: 0.7862 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 861/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 862/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4436 - accuracy: 0.7862 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 863/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4433 - accuracy: 0.7862 - val_loss: 0.5043 - val_accuracy: 0.7561\n",
            "Epoch 864/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4432 - accuracy: 0.7841 - val_loss: 0.5039 - val_accuracy: 0.7480\n",
            "Epoch 865/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4433 - accuracy: 0.7821 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 866/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 867/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 868/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4427 - accuracy: 0.7862 - val_loss: 0.5042 - val_accuracy: 0.7561\n",
            "Epoch 869/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.5041 - val_accuracy: 0.7480\n",
            "Epoch 870/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
            "Epoch 871/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4426 - accuracy: 0.7841 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
            "Epoch 872/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 873/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7561\n",
            "Epoch 874/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 875/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
            "Epoch 876/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4424 - accuracy: 0.7821 - val_loss: 0.5043 - val_accuracy: 0.7561\n",
            "Epoch 877/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4429 - accuracy: 0.7862 - val_loss: 0.5042 - val_accuracy: 0.7480\n",
            "Epoch 878/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4428 - accuracy: 0.7841 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
            "Epoch 879/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4423 - accuracy: 0.7821 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
            "Epoch 880/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4424 - accuracy: 0.7862 - val_loss: 0.5043 - val_accuracy: 0.7480\n",
            "Epoch 881/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
            "Epoch 882/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4425 - accuracy: 0.7862 - val_loss: 0.5046 - val_accuracy: 0.7480\n",
            "Epoch 883/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4425 - accuracy: 0.7841 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 884/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
            "Epoch 885/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4425 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 886/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4423 - accuracy: 0.7841 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
            "Epoch 887/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4434 - accuracy: 0.7862 - val_loss: 0.5048 - val_accuracy: 0.7561\n",
            "Epoch 888/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4419 - accuracy: 0.7862 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
            "Epoch 889/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
            "Epoch 890/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4424 - accuracy: 0.7862 - val_loss: 0.5045 - val_accuracy: 0.7480\n",
            "Epoch 891/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4417 - accuracy: 0.7821 - val_loss: 0.5049 - val_accuracy: 0.7561\n",
            "Epoch 892/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7480\n",
            "Epoch 893/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4419 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7480\n",
            "Epoch 894/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4417 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 895/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4424 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 896/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7561\n",
            "Epoch 897/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 898/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4418 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 899/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4414 - accuracy: 0.7862 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 900/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 901/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4426 - accuracy: 0.7841 - val_loss: 0.5048 - val_accuracy: 0.7480\n",
            "Epoch 902/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4418 - accuracy: 0.7862 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 903/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4422 - accuracy: 0.7800 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 904/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4416 - accuracy: 0.7841 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 905/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7923 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 906/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4414 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7561\n",
            "Epoch 907/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 908/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7841 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
            "Epoch 909/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4413 - accuracy: 0.7902 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 910/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7480\n",
            "Epoch 911/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4412 - accuracy: 0.7902 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 912/1000\n",
            "491/491 [==============================] - 0s 51us/step - loss: 0.4414 - accuracy: 0.7862 - val_loss: 0.5053 - val_accuracy: 0.7561\n",
            "Epoch 913/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4407 - accuracy: 0.7862 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 914/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4406 - accuracy: 0.7902 - val_loss: 0.5053 - val_accuracy: 0.7561\n",
            "Epoch 915/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4408 - accuracy: 0.7862 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
            "Epoch 916/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4407 - accuracy: 0.7902 - val_loss: 0.5051 - val_accuracy: 0.7480\n",
            "Epoch 917/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 918/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4409 - accuracy: 0.7902 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 919/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4408 - accuracy: 0.7841 - val_loss: 0.5051 - val_accuracy: 0.7480\n",
            "Epoch 920/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4422 - accuracy: 0.7923 - val_loss: 0.5056 - val_accuracy: 0.7561\n",
            "Epoch 921/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4407 - accuracy: 0.7841 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 922/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4406 - accuracy: 0.7862 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
            "Epoch 923/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4411 - accuracy: 0.7902 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
            "Epoch 924/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4418 - accuracy: 0.7821 - val_loss: 0.5050 - val_accuracy: 0.7480\n",
            "Epoch 925/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4407 - accuracy: 0.7902 - val_loss: 0.5054 - val_accuracy: 0.7480\n",
            "Epoch 926/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4403 - accuracy: 0.7862 - val_loss: 0.5051 - val_accuracy: 0.7480\n",
            "Epoch 927/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4411 - accuracy: 0.7862 - val_loss: 0.5053 - val_accuracy: 0.7480\n",
            "Epoch 928/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4416 - accuracy: 0.7862 - val_loss: 0.5056 - val_accuracy: 0.7561\n",
            "Epoch 929/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4411 - accuracy: 0.7841 - val_loss: 0.5053 - val_accuracy: 0.7480\n",
            "Epoch 930/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.4402 - accuracy: 0.7902 - val_loss: 0.5055 - val_accuracy: 0.7480\n",
            "Epoch 931/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7561\n",
            "Epoch 932/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7480\n",
            "Epoch 933/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4408 - accuracy: 0.7862 - val_loss: 0.5053 - val_accuracy: 0.7480\n",
            "Epoch 934/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7480\n",
            "Epoch 935/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4413 - accuracy: 0.7862 - val_loss: 0.5053 - val_accuracy: 0.7480\n",
            "Epoch 936/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4408 - accuracy: 0.7841 - val_loss: 0.5054 - val_accuracy: 0.7480\n",
            "Epoch 937/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 938/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 939/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 940/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4401 - accuracy: 0.7902 - val_loss: 0.5056 - val_accuracy: 0.7480\n",
            "Epoch 941/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4407 - accuracy: 0.7821 - val_loss: 0.5056 - val_accuracy: 0.7480\n",
            "Epoch 942/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4412 - accuracy: 0.7862 - val_loss: 0.5055 - val_accuracy: 0.7480\n",
            "Epoch 943/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7480\n",
            "Epoch 944/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4398 - accuracy: 0.7821 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 945/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7480\n",
            "Epoch 946/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7398\n",
            "Epoch 947/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4398 - accuracy: 0.7841 - val_loss: 0.5057 - val_accuracy: 0.7398\n",
            "Epoch 948/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4400 - accuracy: 0.7862 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 949/1000\n",
            "491/491 [==============================] - 0s 29us/step - loss: 0.4395 - accuracy: 0.7841 - val_loss: 0.5058 - val_accuracy: 0.7480\n",
            "Epoch 950/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7480\n",
            "Epoch 951/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7862 - val_loss: 0.5056 - val_accuracy: 0.7480\n",
            "Epoch 952/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4405 - accuracy: 0.7862 - val_loss: 0.5056 - val_accuracy: 0.7480\n",
            "Epoch 953/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4397 - accuracy: 0.7923 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 954/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4396 - accuracy: 0.7862 - val_loss: 0.5058 - val_accuracy: 0.7480\n",
            "Epoch 955/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4399 - accuracy: 0.7862 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 956/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7480\n",
            "Epoch 957/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7480\n",
            "Epoch 958/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4392 - accuracy: 0.7943 - val_loss: 0.5060 - val_accuracy: 0.7398\n",
            "Epoch 959/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4394 - accuracy: 0.7902 - val_loss: 0.5058 - val_accuracy: 0.7480\n",
            "Epoch 960/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4401 - accuracy: 0.7902 - val_loss: 0.5062 - val_accuracy: 0.7398\n",
            "Epoch 961/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4402 - accuracy: 0.7800 - val_loss: 0.5059 - val_accuracy: 0.7398\n",
            "Epoch 962/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4402 - accuracy: 0.7800 - val_loss: 0.5062 - val_accuracy: 0.7398\n",
            "Epoch 963/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7480\n",
            "Epoch 964/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7480\n",
            "Epoch 965/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4401 - accuracy: 0.7862 - val_loss: 0.5063 - val_accuracy: 0.7480\n",
            "Epoch 966/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4399 - accuracy: 0.7841 - val_loss: 0.5068 - val_accuracy: 0.7480\n",
            "Epoch 967/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4398 - accuracy: 0.7902 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 968/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4388 - accuracy: 0.7923 - val_loss: 0.5058 - val_accuracy: 0.7480\n",
            "Epoch 969/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7480\n",
            "Epoch 970/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4391 - accuracy: 0.7862 - val_loss: 0.5057 - val_accuracy: 0.7480\n",
            "Epoch 971/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7480\n",
            "Epoch 972/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4389 - accuracy: 0.7902 - val_loss: 0.5059 - val_accuracy: 0.7480\n",
            "Epoch 973/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4388 - accuracy: 0.7862 - val_loss: 0.5060 - val_accuracy: 0.7480\n",
            "Epoch 974/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4390 - accuracy: 0.7821 - val_loss: 0.5066 - val_accuracy: 0.7480\n",
            "Epoch 975/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5062 - val_accuracy: 0.7480\n",
            "Epoch 976/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5063 - val_accuracy: 0.7480\n",
            "Epoch 977/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4395 - accuracy: 0.7841 - val_loss: 0.5060 - val_accuracy: 0.7398\n",
            "Epoch 978/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4389 - accuracy: 0.7862 - val_loss: 0.5060 - val_accuracy: 0.7480\n",
            "Epoch 979/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4384 - accuracy: 0.7902 - val_loss: 0.5061 - val_accuracy: 0.7480\n",
            "Epoch 980/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5062 - val_accuracy: 0.7480\n",
            "Epoch 981/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4394 - accuracy: 0.7902 - val_loss: 0.5065 - val_accuracy: 0.7480\n",
            "Epoch 982/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5063 - val_accuracy: 0.7480\n",
            "Epoch 983/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5067 - val_accuracy: 0.7398\n",
            "Epoch 984/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4393 - accuracy: 0.7902 - val_loss: 0.5068 - val_accuracy: 0.7398\n",
            "Epoch 985/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4395 - accuracy: 0.7902 - val_loss: 0.5064 - val_accuracy: 0.7398\n",
            "Epoch 986/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5067 - val_accuracy: 0.7398\n",
            "Epoch 987/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4394 - accuracy: 0.7902 - val_loss: 0.5068 - val_accuracy: 0.7398\n",
            "Epoch 988/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4380 - accuracy: 0.7841 - val_loss: 0.5064 - val_accuracy: 0.7480\n",
            "Epoch 989/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4389 - accuracy: 0.7902 - val_loss: 0.5063 - val_accuracy: 0.7480\n",
            "Epoch 990/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4381 - accuracy: 0.7862 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
            "Epoch 991/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4393 - accuracy: 0.7923 - val_loss: 0.5064 - val_accuracy: 0.7480\n",
            "Epoch 992/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4382 - accuracy: 0.7862 - val_loss: 0.5064 - val_accuracy: 0.7398\n",
            "Epoch 993/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4379 - accuracy: 0.7923 - val_loss: 0.5065 - val_accuracy: 0.7480\n",
            "Epoch 994/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4384 - accuracy: 0.7780 - val_loss: 0.5072 - val_accuracy: 0.7480\n",
            "Epoch 995/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4382 - accuracy: 0.7923 - val_loss: 0.5067 - val_accuracy: 0.7480\n",
            "Epoch 996/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7480\n",
            "Epoch 997/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4383 - accuracy: 0.7923 - val_loss: 0.5066 - val_accuracy: 0.7398\n",
            "Epoch 998/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4397 - accuracy: 0.7862 - val_loss: 0.5066 - val_accuracy: 0.7480\n",
            "Epoch 999/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.5066 - val_accuracy: 0.7480\n",
            "Epoch 1000/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4378 - accuracy: 0.7800 - val_loss: 0.5069 - val_accuracy: 0.7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lt87icIqPaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "8063ea2a-8559-4bce-a8f1-c9e34d1fe49a"
      },
      "source": [
        "# visualize the training loss & the validation loss to see if the model is overfitting\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xi5Nr-yrQmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "35e06238-de4f-4036-81d7-032e120a539d"
      },
      "source": [
        "# visualize the training accuracy & the validation accuracy to see if the model is overfitting\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UIY-hvutlRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5d23d111-8cfb-4b38-adc5-630711bed278"
      },
      "source": [
        "# make a prediction & print the actual values\n",
        "prediction = model.predict(X_test)\n",
        "prediction = [1 if y>=0.5 else 0 for y in prediction]\n",
        "print(prediction)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
            "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Dnv2AXtvNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "158150cc-af68-4c33-9f88-d0dae5120ef8"
      },
      "source": [
        "# evaluate the model on the training dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_train)\n",
        "pred = [1 if y>=0.5 else 0 for y in pred]\n",
        "print(classification_report(y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_train,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.88      0.84       398\n",
            "         1.0       0.73      0.61      0.66       216\n",
            "\n",
            "    accuracy                           0.78       614\n",
            "   macro avg       0.77      0.74      0.75       614\n",
            "weighted avg       0.78      0.78      0.78       614\n",
            "\n",
            "Confusion Matrix: \n",
            " [[349  49]\n",
            " [ 84 132]]\n",
            "\n",
            "Accuracy:  0.7833876221498371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmGfeM83uqk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2ca4065e-2f77-405f-9bd4-ba9f9b54c598"
      },
      "source": [
        "# evaluate the model on the testing dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "pred = [1 if y>=0.5 else 0 for y in pred]\n",
        "print(classification_report(y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.82      0.82       102\n",
            "         1.0       0.65      0.65      0.65        52\n",
            "\n",
            "    accuracy                           0.77       154\n",
            "   macro avg       0.74      0.74      0.74       154\n",
            "weighted avg       0.77      0.77      0.77       154\n",
            "\n",
            "Confusion Matrix: \n",
            " [[84 18]\n",
            " [18 34]]\n",
            "\n",
            "Accuracy:  0.7662337662337663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqKE1za1zDle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}